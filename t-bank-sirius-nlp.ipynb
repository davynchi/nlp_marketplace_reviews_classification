{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13086146,"sourceType":"datasetVersion","datasetId":8288504},{"sourceId":13095753,"sourceType":"datasetVersion","datasetId":8295099}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-18T08:37:15.039791Z","iopub.execute_input":"2025-09-18T08:37:15.039978Z","iopub.status.idle":"2025-09-18T08:37:15.432758Z","shell.execute_reply.started":"2025-09-18T08:37:15.039961Z","shell.execute_reply":"2025-09-18T08:37:15.432045Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/tbank-predictions/train_augmented.parquet\n/kaggle/input/tbank-predictions/synthetic_data.parquet\n/kaggle/input/tbank-predictions/train_with_labels.parquet\n/kaggle/input/tbank-predictions/snorkel_predictions.parquet\n/kaggle/input/t-bank-nlp/submission_example.csv\n/kaggle/input/t-bank-nlp/categories.txt\n/kaggle/input/t-bank-nlp/README.md\n/kaggle/input/t-bank-nlp/train.csv\n/kaggle/input/t-bank-nlp/test.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/working'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T08:37:15.433608Z","iopub.execute_input":"2025-09-18T08:37:15.434057Z","iopub.status.idle":"2025-09-18T08:37:15.438733Z","shell.execute_reply.started":"2025-09-18T08:37:15.434030Z","shell.execute_reply":"2025-09-18T08:37:15.438099Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\ndf_train = pd.read_csv('/kaggle/input/t-bank-nlp/train.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T08:37:15.440631Z","iopub.execute_input":"2025-09-18T08:37:15.440875Z","iopub.status.idle":"2025-09-18T08:37:15.482758Z","shell.execute_reply.started":"2025-09-18T08:37:15.440851Z","shell.execute_reply":"2025-09-18T08:37:15.482116Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"categories = pd.read_csv('/kaggle/input/t-bank-nlp/categories.txt')\ncategories.values.flatten()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T08:37:15.483460Z","iopub.execute_input":"2025-09-18T08:37:15.483704Z","iopub.status.idle":"2025-09-18T08:37:15.494150Z","shell.execute_reply.started":"2025-09-18T08:37:15.483682Z","shell.execute_reply":"2025-09-18T08:37:15.493503Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"array(['обувь', 'одежда', 'посуда', 'текстиль', 'товары для детей',\n       'украшения и аксессуары', 'электроника', 'нет товара'],\n      dtype=object)"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"df_test = pd.read_csv('/kaggle/input/t-bank-nlp/test.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T08:37:15.494861Z","iopub.execute_input":"2025-09-18T08:37:15.495064Z","iopub.status.idle":"2025-09-18T08:37:15.551695Z","shell.execute_reply.started":"2025-09-18T08:37:15.495039Z","shell.execute_reply":"2025-09-18T08:37:15.550916Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"План на разметку данных:\n1. Разметить выборку через регулярку\n2. Разметить выборку через какую-нибудь модельку\n3. Выбрать предсказание, взяв предсказания с весами.\n\nДалее нужно сгенерировать синтетические данные на основе имеющихся.\nДалее нужно зааугментировать данные через вставку синонимов, убирание слов, опечатки, замену местами соседних слов.\nПотом QLoRA, PEFT, Fine-Tuning.\n\n[Полезная статья про Snorkel для разметки.](http://habr.com/ru/companies/mts_ai/articles/673786/)","metadata":{}},{"cell_type":"code","source":"CLASSES = ['обувь','одежда','посуда','текстиль','товары для детей',\n           'украшения и аксессуары','электроника','нет товара']\nIDX = {c:i for i,c in enumerate(CLASSES)}\nABSTAIN = -1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-15T08:19:58.569730Z","iopub.execute_input":"2025-09-15T08:19:58.569994Z","iopub.status.idle":"2025-09-15T08:19:58.577047Z","shell.execute_reply.started":"2025-09-15T08:19:58.569969Z","shell.execute_reply":"2025-09-15T08:19:58.576245Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"df_train[df_train['text'].str.contains(r'подошв')]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-15T08:19:58.577807Z","iopub.execute_input":"2025-09-15T08:19:58.578114Z","iopub.status.idle":"2025-09-15T08:19:58.599149Z","shell.execute_reply.started":"2025-09-15T08:19:58.578082Z","shell.execute_reply":"2025-09-15T08:19:58.598238Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"                                                  text\n853  Маленькие. Когда одеваешь рисунка почти нет. Б...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>853</th>\n      <td>Маленькие. Когда одеваешь рисунка почти нет. Б...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":15},{"cell_type":"markdown","source":"## Предобработка","metadata":{}},{"cell_type":"code","source":"df_train['text'] = df_train['text'].apply(lambda x: x.strip().lower().replace('\\r', '\\n'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T08:37:15.552365Z","iopub.execute_input":"2025-09-18T08:37:15.552581Z","iopub.status.idle":"2025-09-18T08:37:15.562635Z","shell.execute_reply.started":"2025-09-18T08:37:15.552564Z","shell.execute_reply":"2025-09-18T08:37:15.561842Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"df_train","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T08:37:15.563362Z","iopub.execute_input":"2025-09-18T08:37:15.563638Z","iopub.status.idle":"2025-09-18T08:37:15.608604Z","shell.execute_reply.started":"2025-09-18T08:37:15.563607Z","shell.execute_reply":"2025-09-18T08:37:15.608082Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                                   text\n0     заказали 14.10.2017 , получили 25.10.2017 \\n\\n...\n1     футболка хорошего качества,но футболка не как ...\n2                                        все отлично!!!\n3     рисунок не очень чёткий, а ткань прозрачная, в...\n4     плохо!!!низ рваный..деньги не вернули!открыла ...\n...                                                 ...\n1813  спасибо,подошло по размеру.все понравилось в п...\n1814  доставка быстрая, до саратова около 2 недель. ...\n1815  на внешний вид шапка нормальная, на большой об...\n1816    за 4 месяца товар так и не дошел до покупателя.\n1817                    прислал пальто вместо куртки!!!\n\n[1818 rows x 1 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>заказали 14.10.2017 , получили 25.10.2017 \\n\\n...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>футболка хорошего качества,но футболка не как ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>все отлично!!!</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>рисунок не очень чёткий, а ткань прозрачная, в...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>плохо!!!низ рваный..деньги не вернули!открыла ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1813</th>\n      <td>спасибо,подошло по размеру.все понравилось в п...</td>\n    </tr>\n    <tr>\n      <th>1814</th>\n      <td>доставка быстрая, до саратова около 2 недель. ...</td>\n    </tr>\n    <tr>\n      <th>1815</th>\n      <td>на внешний вид шапка нормальная, на большой об...</td>\n    </tr>\n    <tr>\n      <th>1816</th>\n      <td>за 4 месяца товар так и не дошел до покупателя.</td>\n    </tr>\n    <tr>\n      <th>1817</th>\n      <td>прислал пальто вместо куртки!!!</td>\n    </tr>\n  </tbody>\n</table>\n<p>1818 rows × 1 columns</p>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"df_test['text'] = df_test['text'].apply(lambda x: x.strip().lower().replace('\\r', '\\n'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T08:37:15.609040Z","iopub.execute_input":"2025-09-18T08:37:15.609236Z","iopub.status.idle":"2025-09-18T08:37:15.631905Z","shell.execute_reply.started":"2025-09-18T08:37:15.609219Z","shell.execute_reply":"2025-09-18T08:37:15.631334Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# df_train['text'] = df_train['text'].fillna(\"\")\ndf_test['text'] = df_test['text'].fillna(\"\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T08:37:15.633804Z","iopub.execute_input":"2025-09-18T08:37:15.634155Z","iopub.status.idle":"2025-09-18T08:37:15.638733Z","shell.execute_reply.started":"2025-09-18T08:37:15.634137Z","shell.execute_reply":"2025-09-18T08:37:15.638143Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"df_test[df_test['text'] == '']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T08:37:15.639443Z","iopub.execute_input":"2025-09-18T08:37:15.639685Z","iopub.status.idle":"2025-09-18T08:37:15.662695Z","shell.execute_reply.started":"2025-09-18T08:37:15.639667Z","shell.execute_reply":"2025-09-18T08:37:15.661306Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"Empty DataFrame\nColumns: [text]\nIndex: []","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"## Загрузим модель, составим промт, дадим вероятности категории","metadata":{}},{"cell_type":"markdown","source":"### LLM для разметки","metadata":{}},{"cell_type":"code","source":"!pip install -U transformers accelerate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T11:10:59.528225Z","iopub.execute_input":"2025-09-14T11:10:59.528881Z","iopub.status.idle":"2025-09-14T11:12:27.037115Z","shell.execute_reply.started":"2025-09-14T11:10:59.528860Z","shell.execute_reply":"2025-09-14T11:12:27.036425Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\nCollecting transformers\n  Downloading transformers-4.56.1-py3-none-any.whl.metadata (42 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.8.1)\nCollecting accelerate\n  Downloading accelerate-1.10.1-py3-none-any.whl.metadata (19 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nCollecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n  Downloading huggingface_hub-0.34.4-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.4)\nCollecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n  Downloading tokenizers-0.22.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (7.0.0)\nRequirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.5.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.5)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nDownloading transformers-4.56.1-py3-none-any.whl (11.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m94.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m:01\u001b[0m\n\u001b[?25hDownloading accelerate-1.10.1-py3-none-any.whl (374 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.9/374.9 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading huggingface_hub-0.34.4-py3-none-any.whl (561 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m561.5/561.5 kB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tokenizers-0.22.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m79.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m88.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m73.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, huggingface-hub, tokenizers, nvidia-cusolver-cu12, transformers, accelerate\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: huggingface-hub\n    Found existing installation: huggingface-hub 0.33.1\n    Uninstalling huggingface-hub-0.33.1:\n      Successfully uninstalled huggingface-hub-0.33.1\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.21.2\n    Uninstalling tokenizers-0.21.2:\n      Successfully uninstalled tokenizers-0.21.2\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.52.4\n    Uninstalling transformers-4.52.4:\n      Successfully uninstalled transformers-4.52.4\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 1.8.1\n    Uninstalling accelerate-1.8.1:\n      Successfully uninstalled accelerate-1.8.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndatasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.5.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed accelerate-1.10.1 huggingface-hub-0.34.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 tokenizers-0.22.0 transformers-4.56.1\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"!pip install -U bitsandbytes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T11:12:27.038131Z","iopub.execute_input":"2025-09-14T11:12:27.038377Z","iopub.status.idle":"2025-09-14T11:12:35.613015Z","shell.execute_reply.started":"2025-09-14T11:12:27.038350Z","shell.execute_reply":"2025-09-14T11:12:35.612270Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Collecting bitsandbytes\n  Downloading bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl.metadata (11 kB)\nRequirement already satisfied: torch<3,>=2.2 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (4.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2025.5.1)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.2->bitsandbytes) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.2->bitsandbytes) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->bitsandbytes) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->bitsandbytes) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\nDownloading bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl (61.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: bitsandbytes\nSuccessfully installed bitsandbytes-0.47.0\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"import torch, os, platform\nprint(\"torch:\", torch.__version__, \"CUDA:\", torch.version.cuda)\nprint(\"GPU visible:\", os.environ.get(\"CUDA_VISIBLE_DEVICES\"))\nprint(platform.platform())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T11:12:35.613984Z","iopub.execute_input":"2025-09-14T11:12:35.614255Z","iopub.status.idle":"2025-09-14T11:12:38.871607Z","shell.execute_reply.started":"2025-09-14T11:12:35.614216Z","shell.execute_reply":"2025-09-14T11:12:38.870941Z"}},"outputs":[{"name":"stdout","text":"torch: 2.6.0+cu124 CUDA: 12.4\nGPU visible: None\nLinux-6.6.56+-x86_64-with-glibc2.35\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"import gc, torch\ngc.collect()\nif torch.cuda.is_available():\n    torch.cuda.empty_cache()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T11:12:38.872292Z","iopub.execute_input":"2025-09-14T11:12:38.872761Z","iopub.status.idle":"2025-09-14T11:12:39.043379Z","shell.execute_reply.started":"2025-09-14T11:12:38.872728Z","shell.execute_reply":"2025-09-14T11:12:39.042524Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"from transformers import BitsAndBytesConfig\nDTYPE = torch.bfloat16 if torch.cuda.get_device_capability()[0] >= 8 else torch.float16\nbnb_cfg = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_compute_dtype=DTYPE, bnb_4bit_use_double_quant=True, bnb_4bit_quant_type=\"nf4\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T11:12:39.044339Z","iopub.execute_input":"2025-09-14T11:12:39.044732Z","iopub.status.idle":"2025-09-14T11:12:40.175060Z","shell.execute_reply.started":"2025-09-14T11:12:39.044706Z","shell.execute_reply":"2025-09-14T11:12:40.174294Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForCausalLM\nimport torch\ntorch.manual_seed(42)\n\nmodel_name = \"t-tech/T-lite-it-1.0\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\ntokenizer.pad_token_id = tokenizer.eos_token_id\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    device_map=\"auto\",\n    low_cpu_mem_usage=True,\n    offload_state_dict=True,\n    quantization_config=bnb_cfg,\n)\nfor param in model.parameters():\n    param.requires_grad = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T11:14:54.433054Z","iopub.execute_input":"2025-09-14T11:14:54.433340Z","iopub.status.idle":"2025-09-14T11:18:10.149105Z","shell.execute_reply.started":"2025-09-14T11:14:54.433320Z","shell.execute_reply":"2025-09-14T11:18:10.148518Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9e9055774dc47b2917204544d4ca013"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a7ef18a10f14823b256ee4bafcd56a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"442c78a4cdf84d338e79fdaeb626f605"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71ed6fa55b82431a8c878a03a759f7de"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/712 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4453fb9ad8b4d8aa0c5d2b971e689d9"}},"metadata":{}},{"name":"stderr","text":"2025-09-14 11:14:59.030041: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1757848499.236878      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1757848499.291970      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd200f7dd736474a8078cffbf7fc0d09"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52226f96ff334a3e90e8f63f32b18f11"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00004.safetensors:   0%|          | 0.00/4.93G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cbc02b9f821947199a6f30e6aac6716a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00004.safetensors:   0%|          | 0.00/4.33G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"66dfb2500dde4024abadf52860253499"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00004.safetensors:   0%|          | 0.00/1.09G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5fa057aa27604b72b058c30b4bfa98ac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00004.safetensors:   0%|          | 0.00/4.87G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c46e8ec7d329443481e89e2337c9ae64"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45fe809c00bd493fa9d1a99c6d1da9d8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/242 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15b053e42ed34c2eb20d653de08da362"}},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"classificator_prompt = '''\nSystem: Ты — аккуратный классификатор отзывов маркетплейса по категориям товаров, к которым они относятся.\nДоступные метки:\nобувь,\nодежда,\nпосуда,\nтекстиль,\nтовары для детей,\nукрашения и аксессуары,\nэлектроника,\nнет товара.\n\nПравила:\n- Если отзыв только про доставку/продавца/деньги/спор без товара → \"нет товара\".\n- Если не ясно, какой товар — тоже \"нет товара\".\n- Выбери ровно одну метку.\n\nОтветь строго JSON одной строкой:\n{\"label\": \"<одна метка>\", \"confidence\": 0..1, \"reason\": \"<до 12 слов>\"}\n\nПримеры:\n\nОтзыв: отличная блузка отслеживалась пришла за 10 дней.\nОтвет: {\"label\": \"одежда\", \"confidence\": 1, \"reason\": \"блузка относится к одежде\"}\n\nОтзыв: Лучшая покупка на алиэкспресс !!)))\nОтвет: {\"label\": \"нет товара\", \"confidence\": 1, \"reason\": \"нет никакого описания товара\"}\n\nОтзыв: На фото они матовые, а пришли глянцевые.\nОтвет: {\"label\": \"обувь\", \"confidence\": 0.4, \"reason\": \"матовость и глянцевость в множественном числе, вероятно, относится к обуви\"}\n\nОтзыв: Товар пришёл менее чем за месяц. На мой 44 заказала L пришла необъятных размеров  \nОтвет: {\"label\": \"одежда\", \"confidence\": 0.9, \"reason\": \"Размер L почти всегда относится к одежде\"}\n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T11:18:10.150309Z","iopub.execute_input":"2025-09-14T11:18:10.150866Z","iopub.status.idle":"2025-09-14T11:18:10.155471Z","shell.execute_reply.started":"2025-09-14T11:18:10.150847Z","shell.execute_reply":"2025-09-14T11:18:10.154689Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T11:18:10.156293Z","iopub.execute_input":"2025-09-14T11:18:10.156593Z","iopub.status.idle":"2025-09-14T11:18:10.173168Z","shell.execute_reply.started":"2025-09-14T11:18:10.156567Z","shell.execute_reply":"2025-09-14T11:18:10.172433Z"}},"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"Qwen2ForCausalLM(\n  (model): Qwen2Model(\n    (embed_tokens): Embedding(151665, 3584, padding_idx=151643)\n    (layers): ModuleList(\n      (0-27): 28 x Qwen2DecoderLayer(\n        (self_attn): Qwen2Attention(\n          (q_proj): Linear4bit(in_features=3584, out_features=3584, bias=True)\n          (k_proj): Linear4bit(in_features=3584, out_features=512, bias=True)\n          (v_proj): Linear4bit(in_features=3584, out_features=512, bias=True)\n          (o_proj): Linear4bit(in_features=3584, out_features=3584, bias=False)\n        )\n        (mlp): Qwen2MLP(\n          (gate_proj): Linear4bit(in_features=3584, out_features=18944, bias=False)\n          (up_proj): Linear4bit(in_features=3584, out_features=18944, bias=False)\n          (down_proj): Linear4bit(in_features=18944, out_features=3584, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n        (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n      )\n    )\n    (norm): Qwen2RMSNorm((3584,), eps=1e-06)\n    (rotary_emb): Qwen2RotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=3584, out_features=151665, bias=False)\n)"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"df_train['text'].iloc[110]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T11:18:10.174688Z","iopub.execute_input":"2025-09-14T11:18:10.175048Z","iopub.status.idle":"2025-09-14T11:18:10.184995Z","shell.execute_reply.started":"2025-09-14T11:18:10.175031Z","shell.execute_reply":"2025-09-14T11:18:10.184434Z"}},"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"'товар не пришел. деньги вернули. но продавец хороший и милый. просто, может быть, мне не повезло.'"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"messages = [\n    {\"role\": \"system\", \"content\": classificator_prompt},\n    {\"role\": \"user\", \"content\": df_train['text'].iloc[110]}\n]\ntext = tokenizer.apply_chat_template(\n    messages,\n    tokenize=False,\n    add_generation_prompt=True\n)\nmodel_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n\ngenerated_ids = model.generate(\n    **model_inputs,\n    max_new_tokens=256\n)\ngenerated_ids = [\n    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n]\n\nresponse = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n\nprint(response)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T11:19:29.737977Z","iopub.execute_input":"2025-09-14T11:19:29.738267Z","iopub.status.idle":"2025-09-14T11:19:33.117135Z","shell.execute_reply.started":"2025-09-14T11:19:29.738247Z","shell.execute_reply":"2025-09-14T11:19:33.116341Z"}},"outputs":[{"name":"stdout","text":"{\"label\": \"нет товара\", \"confidence\": 1, \"reason\": \"отзыв только о доставке и продавце\"}\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"sum(p.numel() for p in model.parameters()) / 1024 / 1024 / 1024","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T11:19:35.845063Z","iopub.execute_input":"2025-09-14T11:19:35.845781Z","iopub.status.idle":"2025-09-14T11:19:35.852569Z","shell.execute_reply.started":"2025-09-14T11:19:35.845753Z","shell.execute_reply":"2025-09-14T11:19:35.851853Z"}},"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"4.051357746124268"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"model.device","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T10:28:45.453807Z","iopub.execute_input":"2025-09-14T10:28:45.454421Z","iopub.status.idle":"2025-09-14T10:28:45.458878Z","shell.execute_reply.started":"2025-09-14T10:28:45.454398Z","shell.execute_reply":"2025-09-14T10:28:45.458277Z"}},"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"device(type='cuda', index=0)"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"# Fast batched LLM labeling → adds \"class_from_llm\" and \"llm_confidence\" to df_train\n\nimport re, json, numpy as np\nfrom tqdm.auto import tqdm\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nfrom torch.nn.utils.rnn import pad_sequence\n\nif tokenizer.pad_token is None:\n    tokenizer.pad_token = tokenizer.eos_token\ntokenizer.padding_side = \"left\"  # more efficient for decoder-only generation\n\nmodel.eval()\n\n# --- Helpers: prompt builder, robust JSON parser ---\ndef make_prompt(txt: str) -> str:\n    messages = [\n        {\"role\": \"system\", \"content\": classificator_prompt},   # <- you already defined this\n        {\"role\": \"user\", \"content\": txt},\n    ]\n    return tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n\ndef extract_json(s: str):\n    # Try a quick slice between first '{' and last '}' (common for chatty models)\n    try:\n        i, j = s.find(\"{\"), s.rfind(\"}\")\n        if i != -1 and j != -1 and j > i:\n            return json.loads(s[i:j+1])\n    except Exception:\n        pass\n    # Fallback regex\n    m = re.search(r\"\\{.*\\}\", s, flags=re.S)\n    if m:\n        try:\n            return json.loads(m.group(0))\n        except Exception:\n            return None\n    return None\n\ndef parse_output(text: str):\n    obj = extract_json(text) or {}\n    label = obj.get(\"label\", None)\n    conf  = obj.get(\"confidence\", None)\n    # normalize label\n    if isinstance(label, str):\n        label = label.strip().lower()\n    if label not in CLASSES:\n        # soft match (e.g., extra words)\n        for c in CLASSES:\n            if label and c in label:\n                label = c; break\n    if label not in CLASSES:\n        label = \"нет товара\"   # safe fallback\n    # coerce confidence\n    try:\n        conf = float(conf)\n        if not (0.0 <= conf <= 1.0):\n            conf = 0.5\n    except Exception:\n        conf = 0.5\n    return label, conf\n\n# --- Prepare data ---\ndf_train[\"text\"] = df_train[\"text\"].fillna(\"\").astype(str)\ntexts = df_train[\"text\"].tolist()\n\n# --- Fast batched generation settings ---\nBATCH_SIZE = 8            # ↓ if OOM, ↑ if room\nMAX_INPUT_TOKENS = 512     # cap context for speed\nMAX_NEW_TOKENS = 256        # JSON answer is short\nGEN_KW = dict(\n    max_new_tokens=MAX_NEW_TOKENS,\n    do_sample=False,            # deterministic & fast\n    temperature=0.0,\n    top_p=1.0,\n    eos_token_id=tokenizer.eos_token_id,\n    pad_token_id=tokenizer.pad_token_id,\n)\n\npred_labels, pred_conf = [], []\n\nwith torch.inference_mode():\n    for start in tqdm(range(0, len(texts), BATCH_SIZE), desc=\"LLM labeling\"):\n        batch_texts = texts[start:start+BATCH_SIZE]\n        prompts = [make_prompt(t) for t in batch_texts]\n\n        enc = tokenizer(\n            prompts, return_tensors=\"pt\",\n            padding=True, truncation=True, max_length=MAX_INPUT_TOKENS\n        ).to(model.device)\n\n        input_lengths = enc[\"attention_mask\"].sum(dim=1)  # prompt lengths per sample\n\n        gen = model.generate(**enc, **GEN_KW)\n\n        # Slice out only the newly generated tokens for each row\n        new_tokens = [out_ids[in_len:] for out_ids, in_len in zip(gen, input_lengths)]\n\n        # Pad to a rectangular tensor just for vectorized decode, then decode\n        padded = pad_sequence(new_tokens, batch_first=True, padding_value=tokenizer.pad_token_id)\n        out_texts = tokenizer.batch_decode(padded, skip_special_tokens=True)\n\n        for out in out_texts:\n            lbl, conf = parse_output(out)\n            pred_labels.append(lbl)\n            pred_conf.append(conf)\n\n# --- Attach results to the DataFrame ---\ndf_train[\"class_from_llm\"]   = pred_labels\ndf_train[\"llm_confidence\"]   = pred_conf\n\n# Optional quick sanity check\nprint(df_train[\"class_from_llm\"].value_counts(dropna=False))\nprint(f\"Mean confidence: {np.mean(pred_conf):.3f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T11:21:39.181701Z","iopub.execute_input":"2025-09-14T11:21:39.182014Z","iopub.status.idle":"2025-09-14T12:28:50.727569Z","shell.execute_reply.started":"2025-09-14T11:21:39.181992Z","shell.execute_reply":"2025-09-14T12:28:50.726838Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"LLM labeling:   0%|          | 0/228 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3e0c16572db409f9d21dc2b2f0e6574"}},"metadata":{}},{"name":"stderr","text":"A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\nA decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\nA decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\nA decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\nA decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\nA decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\nA decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\nA decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\nA decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","output_type":"stream"},{"name":"stdout","text":"class_from_llm\nодежда                    1133\nнет товара                 568\nобувь                       55\nтекстиль                    28\nукрашения и аксессуары      19\nпосуда                      11\nтовары для детей             4\nName: count, dtype: int64\nMean confidence: 0.847\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"df_train.to_parquet('train_predictions.parquet')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T12:33:50.323198Z","iopub.execute_input":"2025-09-14T12:33:50.323500Z","iopub.status.idle":"2025-09-14T12:33:50.494844Z","shell.execute_reply.started":"2025-09-14T12:33:50.323479Z","shell.execute_reply":"2025-09-14T12:33:50.494251Z"}},"outputs":[],"execution_count":42},{"cell_type":"markdown","source":"## Snorkel для разметки","metadata":{}},{"cell_type":"code","source":"!pip install snorkel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-15T08:03:25.332966Z","iopub.execute_input":"2025-09-15T08:03:25.333442Z","iopub.status.idle":"2025-09-15T08:04:36.403684Z","shell.execute_reply.started":"2025-09-15T08:03:25.333420Z","shell.execute_reply":"2025-09-15T08:04:36.402722Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Collecting snorkel\n  Downloading snorkel-0.10.0-py3-none-any.whl.metadata (9.5 kB)\nCollecting munkres>=1.0.6 (from snorkel)\n  Downloading munkres-1.1.4-py2.py3-none-any.whl.metadata (980 bytes)\nRequirement already satisfied: numpy>=1.24.0 in /usr/local/lib/python3.11/dist-packages (from snorkel) (1.26.4)\nRequirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from snorkel) (1.15.3)\nRequirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from snorkel) (2.2.3)\nRequirement already satisfied: tqdm>=4.33.0 in /usr/local/lib/python3.11/dist-packages (from snorkel) (4.67.1)\nRequirement already satisfied: scikit-learn>=0.20.2 in /usr/local/lib/python3.11/dist-packages (from snorkel) (1.2.2)\nRequirement already satisfied: torch>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from snorkel) (2.6.0+cu124)\nRequirement already satisfied: tensorboard>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from snorkel) (2.18.0)\nRequirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from snorkel) (3.20.3)\nRequirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.11/dist-packages (from snorkel) (3.5)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.0->snorkel) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.0->snorkel) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.0->snorkel) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.0->snorkel) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.0->snorkel) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.0->snorkel) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->snorkel) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->snorkel) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->snorkel) (2025.2)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.2->snorkel) (1.5.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.2->snorkel) (3.6.0)\nRequirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.13.0->snorkel) (1.4.0)\nRequirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.13.0->snorkel) (1.73.1)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.13.0->snorkel) (3.8.2)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.13.0->snorkel) (25.0)\nRequirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.13.0->snorkel) (75.2.0)\nRequirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.13.0->snorkel) (1.17.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.13.0->snorkel) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.13.0->snorkel) (3.1.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->snorkel) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->snorkel) (4.14.0)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->snorkel) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->snorkel) (2025.5.1)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.2.0->snorkel)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.2.0->snorkel)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.2.0->snorkel)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.2.0->snorkel)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.2.0->snorkel)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.2.0->snorkel)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.2.0->snorkel)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.2.0->snorkel)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.2.0->snorkel)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->snorkel) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->snorkel) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->snorkel) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.2.0->snorkel)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->snorkel) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->snorkel) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.2.0->snorkel) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.13.0->snorkel) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.24.0->snorkel) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.24.0->snorkel) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.24.0->snorkel) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.24.0->snorkel) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.24.0->snorkel) (2024.2.0)\nDownloading snorkel-0.10.0-py3-none-any.whl (103 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading munkres-1.1.4-py2.py3-none-any.whl (7.0 kB)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: munkres, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, snorkel\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\nSuccessfully installed munkres-1.1.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 snorkel-0.10.0\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import re, numpy as np\nfrom snorkel.labeling import labeling_function           # decorators still here\nfrom snorkel.labeling import PandasLFApplier       # appliers moved to .apply\nfrom snorkel.labeling.model import LabelModel            # LabelModel lives here\nfrom snorkel.labeling.analysis import LFAnalysis         # analysis lives here\n\nCLASSES = ['обувь','одежда','посуда','текстиль','товары для детей',\n           'украшения и аксессуары','электроника','нет товара']\nIDX = {c:i for i,c in enumerate(CLASSES)}\nABSTAIN = -1\n\n# --- helpers\ndef has(text, rx): return re.search(rx, text, flags=re.I) is not None\n\n# --- LFs (examples; extend!)\n@labeling_function()\ndef lf_shoes_kw(x):\n    if has(x.text, r'\\b(ботинк|сапог|кроссовк|кеды|туфл|угг|босоножк|шл[её]панц|ботильон|валенк|)\\w*\\b'):\n        return IDX['обувь']\n    if has(x.text, r'\\b(стельк|подошв|каблук|колодк)\\w*\\b'):\n        return IDX['обувь']\n    return ABSTAIN\n\n@labeling_function()\ndef lf_clothes_kw(x):\n    if has(x.text, r'(пуховик|куртк|ветровк|футболк|плать|джинс|рубашк|юбк|свитер|кофт|худи|термобель|колготк|пижам|халат|шорт|шарф|шапк|варежк|носки| S | M | L | XL | s | m | l | xl | м | л | с)\\w*'):\n        return IDX['одежда']\n    if has(x.text, r'\\b(рост|обхват|талия|бедра)\\b') or has(x.text, r'(ткан|сшит)'):\n        return IDX['одежда']\n    return ABSTAIN\n\n@labeling_function()\ndef lf_textile_kw(x):\n    if has(x.text, r'(постельн|простын|наволочк|пододеяльник|полотенц|плед|покрывал|штор|тюл|скатерт|отрез ткан)\\w*'):\n        return IDX['текстиль']\n    return ABSTAIN\n\n@labeling_function()\ndef lf_tableware_kw(x):\n    if has(x.text, r'(кружк|тарелк|кастрюл|сковород|ковш|форм[аы] для запекан|бокал|графин|ложк|вилк)\\w*'):\n        return IDX['посуда']\n    return ABSTAIN\n\n@labeling_function()\ndef lf_jewelry_kw(x):\n    if has(x.text, r'(серьг|кольц|браслет|цепочк|кулон|чокер|брош|ремень|перчатк|очки|оправ)\\w*'):\n        return IDX['украшения и аксессуары']\n    return ABSTAIN\n\n@labeling_function()\ndef lf_electronics_kw(x):\n    if has(x.text, r'(телефон|смартфон|наушник|колонк|ноутбук|телевизор|планшет|экран|камер|bluetooth|заряд|кабель|блок питания|ламп(а|очку)|пылесос|фен|триммер|блендер|миксер|электрочайн)\\w*'):\n        return IDX['электроника']\n    return ABSTAIN\n\n@labeling_function()\ndef lf_kids_kw(x):\n    if has(x.text, r'(игрушк|кукл|конструктор|машинк|пазл|коляск|подгузник|бутылочк|соск|слюнявчик|погремушк|развива)\\w*'):\n        return IDX['товары для детей']\n    return ABSTAIN\n\n@labeling_function()\ndef lf_noproduct_service(x):\n    if has(x.text, r'(доставк|курьер|трек|спор|возврат|деньг|продавц|магазин|приложени|оплат|скидк|купон)\\w*'):\n        return IDX['нет товара']\n    if lf_shoes_kw(x) == ABSTAIN and lf_clothes_kw(x) == ABSTAIN and lf_textile_kw(x) == ABSTAIN \\\n      and lf_tableware_kw(x) == ABSTAIN and lf_jewelry_kw(x) == ABSTAIN and lf_electronics_kw(x) == ABSTAIN \\\n      and lf_kids_kw(x) == ABSTAIN:\n        return IDX['нет товара']\n    return ABSTAIN\n\n# @labeling_function()\n# def lf_too_short_generic(x):\n#     if len(re.findall(r'\\w+', x.text)) < 4 or has(x.text, r'товар|вернули'):\n#         return IDX['нет товара']\n#     return ABSTAIN\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-15T08:04:36.405415Z","iopub.execute_input":"2025-09-15T08:04:36.405674Z","iopub.status.idle":"2025-09-15T08:04:40.333789Z","shell.execute_reply.started":"2025-09-15T08:04:36.405650Z","shell.execute_reply":"2025-09-15T08:04:40.333207Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import pandas as pd\nfrom snorkel.labeling import LFAnalysis\n\ndf_snorkel = pd.DataFrame({\n    \"text\": df_train[\"text\"].fillna(\"\").astype(str)\n})\n\nlfs = [lf_shoes_kw, lf_clothes_kw, lf_textile_kw, lf_tableware_kw,\n       lf_jewelry_kw, lf_electronics_kw, lf_kids_kw, lf_noproduct_service]\napplier = PandasLFApplier(lfs)\nL = applier.apply(df=df_snorkel)  # shape (N, num_LFs)\n\nLFAnalysis(L=L, lfs=lfs).lf_summary()\n\nlabel_model = LabelModel(cardinality=len(CLASSES), verbose=True)\nlabel_model.fit(L_train=L, n_epochs=500, log_freq=50, seed=42)\n\nprobs = label_model.predict_proba(L)  # (N, 8)\nlf_pred = probs.argmax(1)\nlf_conf = probs.max(1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-15T08:05:42.026704Z","iopub.execute_input":"2025-09-15T08:05:42.027538Z","iopub.status.idle":"2025-09-15T08:05:46.117706Z","shell.execute_reply.started":"2025-09-15T08:05:42.027506Z","shell.execute_reply":"2025-09-15T08:05:46.116883Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 1818/1818 [00:00<00:00, 5152.09it/s]\n100%|██████████| 500/500 [00:00<00:00, 629.10epoch/s]\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"probs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-15T08:05:49.738068Z","iopub.execute_input":"2025-09-15T08:05:49.738869Z","iopub.status.idle":"2025-09-15T08:05:49.744190Z","shell.execute_reply.started":"2025-09-15T08:05:49.738842Z","shell.execute_reply":"2025-09-15T08:05:49.743213Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"array([[0.17582843, 0.19520215, 0.09854587, ..., 0.09893634, 0.09854664,\n        0.13585023],\n       [0.17582843, 0.19520215, 0.09854587, ..., 0.09893634, 0.09854664,\n        0.13585023],\n       [0.1354755 , 0.1354755 , 0.1186882 , ..., 0.11881734, 0.11868817,\n        0.1354755 ],\n       ...,\n       [0.17582843, 0.19520215, 0.09854587, ..., 0.09893634, 0.09854664,\n        0.13585023],\n       [0.1354755 , 0.1354755 , 0.1186882 , ..., 0.11881734, 0.11868817,\n        0.1354755 ],\n       [0.17582843, 0.19520215, 0.09854587, ..., 0.09893634, 0.09854664,\n        0.13585023]])"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"df_train['prediction_snorkel'] = lf_pred\ndf_train['snorkel_confidence'] = lf_conf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-15T08:06:23.105723Z","iopub.execute_input":"2025-09-15T08:06:23.106000Z","iopub.status.idle":"2025-09-15T08:06:23.111502Z","shell.execute_reply.started":"2025-09-15T08:06:23.105979Z","shell.execute_reply":"2025-09-15T08:06:23.110625Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"df_train[\"snorkel_probs\"] = probs.tolist()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-15T08:08:54.676723Z","iopub.execute_input":"2025-09-15T08:08:54.677004Z","iopub.status.idle":"2025-09-15T08:08:54.687381Z","shell.execute_reply.started":"2025-09-15T08:08:54.676984Z","shell.execute_reply":"2025-09-15T08:08:54.686581Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"df_train","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-15T08:08:58.236639Z","iopub.execute_input":"2025-09-15T08:08:58.237086Z","iopub.status.idle":"2025-09-15T08:08:58.248894Z","shell.execute_reply.started":"2025-09-15T08:08:58.237066Z","shell.execute_reply":"2025-09-15T08:08:58.248176Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"                                                   text  prediction_snorkel  \\\n0     заказали 14.10.2017 , получили 25.10.2017 \\n\\n...                   1   \n1     футболка хорошего качества,но футболка не как ...                   1   \n2                                        все отлично!!!                   0   \n3     рисунок не очень чёткий, а ткань прозрачная, в...                   1   \n4     плохо!!!низ рваный..деньги не вернули!открыла ...                   7   \n...                                                 ...                 ...   \n1813  спасибо,подошло по размеру.все понравилось в п...                   0   \n1814  доставка быстрая, до саратова около 2 недель. ...                   7   \n1815  на внешний вид шапка нормальная, на большой об...                   1   \n1816    за 4 месяца товар так и не дошел до покупателя.                   0   \n1817                    прислал пальто вместо куртки!!!                   1   \n\n      snorkel_confidence                                      snorkel_probs  \n0               0.195202  [0.1758284279266772, 0.19520214640769284, 0.09...  \n1               0.195202  [0.1758284279266772, 0.19520214640769284, 0.09...  \n2               0.135475  [0.1354754974159609, 0.1354754974159609, 0.118...  \n3               0.195202  [0.1758284279266772, 0.19520214640769284, 0.09...  \n4               0.258021  [0.19997417589112063, 0.20251091383449046, 0.0...  \n...                  ...                                                ...  \n1813            0.135475  [0.1354754974159609, 0.1354754974159609, 0.118...  \n1814            0.258021  [0.19997417589112063, 0.20251091383449046, 0.0...  \n1815            0.195202  [0.1758284279266772, 0.19520214640769284, 0.09...  \n1816            0.135475  [0.1354754974159609, 0.1354754974159609, 0.118...  \n1817            0.195202  [0.1758284279266772, 0.19520214640769284, 0.09...  \n\n[1818 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>prediction_snorkel</th>\n      <th>snorkel_confidence</th>\n      <th>snorkel_probs</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>заказали 14.10.2017 , получили 25.10.2017 \\n\\n...</td>\n      <td>1</td>\n      <td>0.195202</td>\n      <td>[0.1758284279266772, 0.19520214640769284, 0.09...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>футболка хорошего качества,но футболка не как ...</td>\n      <td>1</td>\n      <td>0.195202</td>\n      <td>[0.1758284279266772, 0.19520214640769284, 0.09...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>все отлично!!!</td>\n      <td>0</td>\n      <td>0.135475</td>\n      <td>[0.1354754974159609, 0.1354754974159609, 0.118...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>рисунок не очень чёткий, а ткань прозрачная, в...</td>\n      <td>1</td>\n      <td>0.195202</td>\n      <td>[0.1758284279266772, 0.19520214640769284, 0.09...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>плохо!!!низ рваный..деньги не вернули!открыла ...</td>\n      <td>7</td>\n      <td>0.258021</td>\n      <td>[0.19997417589112063, 0.20251091383449046, 0.0...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1813</th>\n      <td>спасибо,подошло по размеру.все понравилось в п...</td>\n      <td>0</td>\n      <td>0.135475</td>\n      <td>[0.1354754974159609, 0.1354754974159609, 0.118...</td>\n    </tr>\n    <tr>\n      <th>1814</th>\n      <td>доставка быстрая, до саратова около 2 недель. ...</td>\n      <td>7</td>\n      <td>0.258021</td>\n      <td>[0.19997417589112063, 0.20251091383449046, 0.0...</td>\n    </tr>\n    <tr>\n      <th>1815</th>\n      <td>на внешний вид шапка нормальная, на большой об...</td>\n      <td>1</td>\n      <td>0.195202</td>\n      <td>[0.1758284279266772, 0.19520214640769284, 0.09...</td>\n    </tr>\n    <tr>\n      <th>1816</th>\n      <td>за 4 месяца товар так и не дошел до покупателя.</td>\n      <td>0</td>\n      <td>0.135475</td>\n      <td>[0.1354754974159609, 0.1354754974159609, 0.118...</td>\n    </tr>\n    <tr>\n      <th>1817</th>\n      <td>прислал пальто вместо куртки!!!</td>\n      <td>1</td>\n      <td>0.195202</td>\n      <td>[0.1758284279266772, 0.19520214640769284, 0.09...</td>\n    </tr>\n  </tbody>\n</table>\n<p>1818 rows × 4 columns</p>\n</div>"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"df_train.loc[1814]['text']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-14T18:36:04.444513Z","iopub.execute_input":"2025-09-14T18:36:04.444867Z","iopub.status.idle":"2025-09-14T18:36:04.451308Z","shell.execute_reply.started":"2025-09-14T18:36:04.444842Z","shell.execute_reply":"2025-09-14T18:36:04.450402Z"}},"outputs":[{"execution_count":70,"output_type":"execute_result","data":{"text/plain":"'доставка быстрая, до саратова около 2 недель. упакована качественно. сшита аккуратно, дефектов не обнаружила. ткань лёгкая, приятна к телу, немного (в меру) прозрачна. м на 44 размер.'"},"metadata":{}}],"execution_count":70},{"cell_type":"code","source":"df_train.to_parquet('snorkel_predictions.parquet')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-15T08:09:13.015356Z","iopub.execute_input":"2025-09-15T08:09:13.015681Z","iopub.status.idle":"2025-09-15T08:09:13.033128Z","shell.execute_reply.started":"2025-09-15T08:09:13.015660Z","shell.execute_reply":"2025-09-15T08:09:13.032292Z"}},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":"## Объединяем предсказания","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\ndf_train_snorkel = pd.read_parquet('/kaggle/input/train-predictions/snorkel_predictions.parquet')\ndf_train_llm = pd.read_parquet('/kaggle/input/train-predictions/llm_predictions.parquet')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-15T08:11:24.397386Z","iopub.execute_input":"2025-09-15T08:11:24.397644Z","iopub.status.idle":"2025-09-15T08:11:24.435733Z","shell.execute_reply.started":"2025-09-15T08:11:24.397628Z","shell.execute_reply":"2025-09-15T08:11:24.435180Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"p_snorkel = df_train_snorkel['snorkel_probs'].values\np_snorkel = np.array(list(p_snorkel))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-15T08:14:07.871089Z","iopub.execute_input":"2025-09-15T08:14:07.871363Z","iopub.status.idle":"2025-09-15T08:14:07.876667Z","shell.execute_reply.started":"2025-09-15T08:14:07.871341Z","shell.execute_reply":"2025-09-15T08:14:07.876098Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"p_snorkel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-15T08:14:08.573331Z","iopub.execute_input":"2025-09-15T08:14:08.573611Z","iopub.status.idle":"2025-09-15T08:14:08.578549Z","shell.execute_reply.started":"2025-09-15T08:14:08.573591Z","shell.execute_reply":"2025-09-15T08:14:08.577997Z"}},"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"array([[0.17582843, 0.19520215, 0.09854587, ..., 0.09893634, 0.09854664,\n        0.13585023],\n       [0.17582843, 0.19520215, 0.09854587, ..., 0.09893634, 0.09854664,\n        0.13585023],\n       [0.1354755 , 0.1354755 , 0.1186882 , ..., 0.11881734, 0.11868817,\n        0.1354755 ],\n       ...,\n       [0.17582843, 0.19520215, 0.09854587, ..., 0.09893634, 0.09854664,\n        0.13585023],\n       [0.1354755 , 0.1354755 , 0.1186882 , ..., 0.11881734, 0.11868817,\n        0.1354755 ],\n       [0.17582843, 0.19520215, 0.09854587, ..., 0.09893634, 0.09854664,\n        0.13585023]])"},"metadata":{}}],"execution_count":39},{"cell_type":"code","source":"import numpy as np\nimport re\n\nCLASSES = ['обувь','одежда','посуда','текстиль','товары для детей',\n           'украшения и аксессуары','электроника','нет товара']\nIDX = {c:i for i,c in enumerate(CLASSES)}\nNO_PRODUCT = IDX['нет товара']\n\ndef build_llm_probs_from_label(lbls, confs, K=8):\n    \"\"\"\n    If you only have LLM hard labels + a confidence in [0,1], build a prob vector:\n    chosen = conf, the remaining mass is spread uniformly across others.\n    \"\"\"\n    P = np.full((len(lbls), K), 0.0, dtype=np.float32)\n    for i, (lab, conf) in enumerate(zip(lbls, confs)):\n        conf = float(conf)\n        conf = min(max(conf, 0.0), 1.0)\n        base = (1.0 - conf) / (K - 1 + 1e-9)\n        P[i, :] = base\n        P[i, IDX[lab]] = conf\n    return P\n\ndef fuse_probs(p_snorkel, p_llm, llm_conf=None, tau_low=0.60,\n               alpha_min=0.20, alpha_max=0.80):\n    \"\"\"\n    p_snorkel: (N,8) Snorkel LabelModel probs\n    p_llm:     (N,8) LLM probs (from votes or build_llm_probs_from_label)\n    llm_conf:  (N,) optional scalar confidence per row; if None -> max(p_llm, axis=1)\n    tau_low:   if fused max prob < tau_low -> force 'нет товара'\n    alpha_*:   LLM weight bounds for per-example mixing\n    Returns: final_labels (N,), final_conf (N,), fused_probs (N,8)\n    \"\"\"\n    eps = 1e-9\n    # normalize & clip\n    pS = np.clip(p_snorkel, eps, 1.0)\n    pS /= pS.sum(1, keepdims=True)\n    pL = np.clip(p_llm, eps, 1.0)\n    pL /= pL.sum(1, keepdims=True)\n\n    # per-example LLM weight from its confidence\n    if llm_conf is None:\n        llm_conf = pL.max(1)\n    llm_conf = np.asarray(llm_conf, dtype=np.float32)\n    alpha = np.clip(alpha_min + (alpha_max - alpha_min) * llm_conf, alpha_min, alpha_max)\n    wL = alpha[:, None]\n    wS = (1.0 - alpha)[:, None]\n\n    # log-linear pooling (more robust than linear mixture)\n    logp = wL * np.log(pL) + wS * np.log(pS)\n    logp -= logp.max(1, keepdims=True)\n    p = np.exp(logp)\n    p /= p.sum(1, keepdims=True)\n\n    y = p.argmax(1)\n    conf = p.max(1)\n\n    # Low-confidence fallback → 'нет товара'\n    low = conf < float(tau_low)\n    y[low] = NO_PRODUCT\n    conf[low] = np.maximum(conf[low], tau_low)  # optional: floor for readability\n\n    return y, conf, p\n\n# Optional tiny guard: if text is service-only and fused conf is not high, force 'нет товара'\nSERVICE_RX = re.compile(r'(доставк|курьер|трек|спор|возврат|деньг|продавц|приложени|оплат)', re.I)\ndef postprocess_service(texts, y, conf, p, tau_service=0.70):\n    for i, t in enumerate(texts):\n        if y[i] != NO_PRODUCT and conf[i] < tau_service and SERVICE_RX.search(t or \"\"):\n            y[i] = NO_PRODUCT\n    return y, conf\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-15T08:14:12.084844Z","iopub.execute_input":"2025-09-15T08:14:12.085419Z","iopub.status.idle":"2025-09-15T08:14:12.095031Z","shell.execute_reply.started":"2025-09-15T08:14:12.085397Z","shell.execute_reply":"2025-09-15T08:14:12.094314Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"p_llm = build_llm_probs_from_label(df_train_llm[\"class_from_llm\"], df_train_llm[\"llm_confidence\"], K=len(CLASSES))\ny, conf, p = fuse_probs(p_snorkel, p_llm, llm_conf=df_train_llm[\"llm_confidence\"], tau_low=0.50)\nfinal_labels = [CLASSES[i] for i in y]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-15T08:14:12.412299Z","iopub.execute_input":"2025-09-15T08:14:12.412597Z","iopub.status.idle":"2025-09-15T08:14:12.436417Z","shell.execute_reply.started":"2025-09-15T08:14:12.412576Z","shell.execute_reply":"2025-09-15T08:14:12.435931Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"from collections import Counter\nCounter(final_labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-15T08:14:14.845364Z","iopub.execute_input":"2025-09-15T08:14:14.846207Z","iopub.status.idle":"2025-09-15T08:14:14.851138Z","shell.execute_reply.started":"2025-09-15T08:14:14.846180Z","shell.execute_reply":"2025-09-15T08:14:14.850404Z"}},"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"Counter({'одежда': 1130,\n         'нет товара': 598,\n         'обувь': 38,\n         'украшения и аксессуары': 18,\n         'текстиль': 28,\n         'товары для детей': 3,\n         'посуда': 3})"},"metadata":{}}],"execution_count":42},{"cell_type":"code","source":"df_train['label'] = final_labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-15T08:14:19.159931Z","iopub.execute_input":"2025-09-15T08:14:19.160430Z","iopub.status.idle":"2025-09-15T08:14:19.164383Z","shell.execute_reply.started":"2025-09-15T08:14:19.160408Z","shell.execute_reply":"2025-09-15T08:14:19.163847Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"df_train.to_parquet('train_with_labels.parquet')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-15T08:14:22.414421Z","iopub.execute_input":"2025-09-15T08:14:22.414987Z","iopub.status.idle":"2025-09-15T08:14:22.428386Z","shell.execute_reply.started":"2025-09-15T08:14:22.414962Z","shell.execute_reply":"2025-09-15T08:14:22.427791Z"}},"outputs":[],"execution_count":44},{"cell_type":"markdown","source":"## Генерируем синтетику","metadata":{}},{"cell_type":"code","source":"!pip install -U transformers accelerate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-15T08:20:18.861826Z","iopub.execute_input":"2025-09-15T08:20:18.862151Z","iopub.status.idle":"2025-09-15T08:22:06.451566Z","shell.execute_reply.started":"2025-09-15T08:20:18.862129Z","shell.execute_reply":"2025-09-15T08:22:06.450516Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\nCollecting transformers\n  Downloading transformers-4.56.1-py3-none-any.whl.metadata (42 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.8.1)\nCollecting accelerate\n  Downloading accelerate-1.10.1-py3-none-any.whl.metadata (19 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nCollecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n  Downloading huggingface_hub-0.34.4-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.4)\nCollecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n  Downloading tokenizers-0.22.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (7.0.0)\nRequirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.5.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.5)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nDownloading transformers-4.56.1-py3-none-any.whl (11.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading accelerate-1.10.1-py3-none-any.whl (374 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.9/374.9 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading huggingface_hub-0.34.4-py3-none-any.whl (561 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m561.5/561.5 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tokenizers-0.22.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m71.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m70.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, huggingface-hub, tokenizers, nvidia-cusolver-cu12, transformers, accelerate\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: huggingface-hub\n    Found existing installation: huggingface-hub 0.33.1\n    Uninstalling huggingface-hub-0.33.1:\n      Successfully uninstalled huggingface-hub-0.33.1\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.21.2\n    Uninstalling tokenizers-0.21.2:\n      Successfully uninstalled tokenizers-0.21.2\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.52.4\n    Uninstalling transformers-4.52.4:\n      Successfully uninstalled transformers-4.52.4\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 1.8.1\n    Uninstalling accelerate-1.8.1:\n      Successfully uninstalled accelerate-1.8.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndatasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.5.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed accelerate-1.10.1 huggingface-hub-0.34.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 tokenizers-0.22.0 transformers-4.56.1\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"CLASSES","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-15T08:22:06.453267Z","iopub.execute_input":"2025-09-15T08:22:06.453517Z","iopub.status.idle":"2025-09-15T08:22:06.460146Z","shell.execute_reply.started":"2025-09-15T08:22:06.453493Z","shell.execute_reply":"2025-09-15T08:22:06.459237Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"['обувь',\n 'одежда',\n 'посуда',\n 'текстиль',\n 'товары для детей',\n 'украшения и аксессуары',\n 'электроника',\n 'нет товара']"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"!pip install -U bitsandbytes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-15T08:22:06.460965Z","iopub.execute_input":"2025-09-15T08:22:06.461547Z","iopub.status.idle":"2025-09-15T08:22:12.850462Z","shell.execute_reply.started":"2025-09-15T08:22:06.461518Z","shell.execute_reply":"2025-09-15T08:22:12.849409Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Collecting bitsandbytes\n  Downloading bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl.metadata (11 kB)\nRequirement already satisfied: torch<3,>=2.2 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (4.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2025.5.1)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.2->bitsandbytes) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.2->bitsandbytes) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->bitsandbytes) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->bitsandbytes) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\nDownloading bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl (61.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: bitsandbytes\nSuccessfully installed bitsandbytes-0.47.0\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"from transformers import BitsAndBytesConfig, AutoTokenizer, AutoModelForCausalLM\nimport torch\n\nDTYPE = torch.bfloat16 if torch.cuda.get_device_capability()[0] >= 8 else torch.float16\nbnb_cfg = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_compute_dtype=torch.float16,\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_quant_type=\"nf4\",\n)\ntorch.manual_seed(42)\n\nmodel_name = \"t-tech/T-lite-it-1.0\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\ntokenizer.pad_token_id = tokenizer.eos_token_id\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    device_map={\"\": 0},   \n    low_cpu_mem_usage=True,\n    offload_state_dict=True,\n    quantization_config=bnb_cfg,\n)\nfor param in model.parameters():\n    param.requires_grad = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-15T09:04:48.421297Z","iopub.execute_input":"2025-09-15T09:04:48.421841Z","iopub.status.idle":"2025-09-15T09:05:46.782146Z","shell.execute_reply.started":"2025-09-15T09:04:48.421816Z","shell.execute_reply":"2025-09-15T09:05:46.781221Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"038bfe13f05145adb68c1d50c4536dad"}},"metadata":{}}],"execution_count":43},{"cell_type":"code","source":"df_train_with_labels = pd.read_parquet('/kaggle/input/train-predictions/train_with_labels.parquet')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-15T08:28:52.986426Z","iopub.execute_input":"2025-09-15T08:28:52.987289Z","iopub.status.idle":"2025-09-15T08:28:53.328834Z","shell.execute_reply.started":"2025-09-15T08:28:52.987261Z","shell.execute_reply":"2025-09-15T08:28:53.328274Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"df_train_with_labels = df_train_with_labels[['text', 'label']]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-15T08:29:21.046253Z","iopub.execute_input":"2025-09-15T08:29:21.047084Z","iopub.status.idle":"2025-09-15T08:29:21.056018Z","shell.execute_reply.started":"2025-09-15T08:29:21.047056Z","shell.execute_reply":"2025-09-15T08:29:21.055198Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"# --- CONFIG ---\nimport os, re, json, math, random, gc\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom tqdm.auto import tqdm\nfrom collections import Counter\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom torch.nn.utils.rnn import pad_sequence\n\nnp.random.seed(42)\nrandom.seed(42)\n\n# Your 8 classes (labels already exist in df_train['label'])\nCLASSES = ['обувь','одежда','посуда','текстиль','товары для детей',\n           'украшения и аксессуары','электроника','нет товара']\n\nassert {'text','label'}.issubset(df_train_with_labels.columns), \"df_train must have columns: text, label\"\n\n# Make sure tokenizer/model are set for batched decoding\ntokenizer.padding_side = \"left\"\nif tokenizer.pad_token_id is None:\n    tokenizer.pad_token_id = tokenizer.eos_token_id\nmodel.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-15T09:05:46.783847Z","iopub.execute_input":"2025-09-15T09:05:46.784225Z","iopub.status.idle":"2025-09-15T09:05:46.795751Z","shell.execute_reply.started":"2025-09-15T09:05:46.784197Z","shell.execute_reply":"2025-09-15T09:05:46.794840Z"}},"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"Qwen2ForCausalLM(\n  (model): Qwen2Model(\n    (embed_tokens): Embedding(151665, 3584, padding_idx=151643)\n    (layers): ModuleList(\n      (0-27): 28 x Qwen2DecoderLayer(\n        (self_attn): Qwen2Attention(\n          (q_proj): Linear4bit(in_features=3584, out_features=3584, bias=True)\n          (k_proj): Linear4bit(in_features=3584, out_features=512, bias=True)\n          (v_proj): Linear4bit(in_features=3584, out_features=512, bias=True)\n          (o_proj): Linear4bit(in_features=3584, out_features=3584, bias=False)\n        )\n        (mlp): Qwen2MLP(\n          (gate_proj): Linear4bit(in_features=3584, out_features=18944, bias=False)\n          (up_proj): Linear4bit(in_features=3584, out_features=18944, bias=False)\n          (down_proj): Linear4bit(in_features=18944, out_features=3584, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n        (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n      )\n    )\n    (norm): Qwen2RMSNorm((3584,), eps=1e-06)\n    (rotary_emb): Qwen2RotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=3584, out_features=151665, bias=False)\n)"},"metadata":{}}],"execution_count":44},{"cell_type":"code","source":"# --- 1) Mine top in-corpus n-grams per class (hints) ---\ndef top_ngrams_for_class(df, label, topk=40, ngram_range=(1,2), min_df=2):\n    texts = df.loc[df['label']==label, 'text'].fillna(\"\").astype(str).tolist()\n    if len(texts) == 0:\n        return []\n    vec = CountVectorizer(ngram_range=ngram_range, min_df=min_df, lowercase=True,\n                          token_pattern=r\"[A-Za-zА-Яа-я0-9ёЁ]+\")\n    X = vec.fit_transform(texts)\n    freqs = np.asarray(X.sum(axis=0)).ravel()\n    vocab = np.array(vec.get_feature_names_out())\n    # Drop overly generic tokens\n    keep = [i for i,t in enumerate(vocab) if len(t) >= 3]\n    idx = np.argsort(freqs[keep])[::-1][:topk]\n    return vocab[keep][idx].tolist()\n\nHINTS = {c: top_ngrams_for_class(df_train_with_labels, c, topk=40) for c in CLASSES}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-15T08:30:24.923659Z","iopub.execute_input":"2025-09-15T08:30:24.924379Z","iopub.status.idle":"2025-09-15T08:30:25.003154Z","shell.execute_reply.started":"2025-09-15T08:30:24.924350Z","shell.execute_reply":"2025-09-15T08:30:25.002230Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"HINTS","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-15T08:30:28.304835Z","iopub.execute_input":"2025-09-15T08:30:28.305186Z","iopub.status.idle":"2025-09-15T08:30:28.311410Z","shell.execute_reply.started":"2025-09-15T08:30:28.305165Z","shell.execute_reply":"2025-09-15T08:30:28.310707Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"{'обувь': ['размер',\n  'очень',\n  'все',\n  'рост',\n  'качество',\n  'носки',\n  'подошёл',\n  'товар',\n  'было',\n  'раз',\n  'отлично',\n  'после',\n  'пришёл',\n  'пришли',\n  'после первой',\n  'первой носки',\n  'первой',\n  'размеру',\n  'на фото',\n  'меня',\n  'как',\n  'доставка',\n  'быстро',\n  'больше',\n  'по размеру',\n  'хорошее',\n  'шел',\n  'что',\n  'хорошо',\n  'фото',\n  'цвет',\n  'месяц',\n  'материал на',\n  'материал',\n  'качество хорошее',\n  'хорошо но',\n  'заказывала',\n  'заказ',\n  'за 2',\n  'есть'],\n 'одежда': ['очень',\n  'размер',\n  'качество',\n  'как',\n  'что',\n  'доставка',\n  'ткань',\n  'платье',\n  'соответствует',\n  'все',\n  'так',\n  'спасибо',\n  'цвет',\n  'рост',\n  'заказала',\n  'быстро',\n  'пришла',\n  'фото',\n  'синтетика',\n  'хорошо',\n  'это',\n  'заказывала',\n  'продавец',\n  'рекомендую',\n  'быстрая',\n  'деньги',\n  'мне',\n  'как на',\n  'не соответствует',\n  'на фото',\n  'нитки',\n  'товар',\n  'материал',\n  'рукава',\n  'размеру',\n  'супер',\n  'хорошая',\n  'только',\n  'даже',\n  'торчат'],\n 'посуда': [],\n 'текстиль': ['ткань',\n  'очень',\n  'синтетика',\n  'только',\n  'качество',\n  'что',\n  'приятная',\n  'как',\n  'хороший',\n  'трусы',\n  'цвет',\n  'чем',\n  'цена',\n  'чуть',\n  'что на',\n  'совсем',\n  'стирки',\n  'телу',\n  'товар',\n  'фото',\n  'приятно',\n  'продавец',\n  'просто',\n  'после стирки',\n  'после',\n  'очень довольна',\n  'ночнушка',\n  'ниток',\n  'неприятная',\n  'приятная в',\n  'смотрится',\n  'не совсем',\n  'недели',\n  'не очень',\n  'на фото',\n  'колется',\n  'много',\n  'картинке',\n  'к телу',\n  'и не'],\n 'товары для детей': ['так', 'рост', 'и вес', 'вес'],\n 'украшения и аксессуары': ['очень',\n  'качество',\n  'стоит',\n  'яркие',\n  'слишком',\n  'раз',\n  'ощупь',\n  'чем',\n  'очень красивые',\n  'носить',\n  'на ощупь',\n  'не очень',\n  'красивые',\n  'как',\n  'выглядит',\n  'быстро'],\n 'электроника': [],\n 'нет товара': ['деньги',\n  'товар',\n  'вернули',\n  'продавец',\n  'заказ',\n  'очень',\n  'так',\n  'товар не',\n  'спор',\n  'пришел',\n  'и не',\n  'пришёл',\n  'не пришел',\n  'так и',\n  'качество',\n  'не пришёл',\n  'не вернули',\n  'месяца',\n  'деньги вернули',\n  'деньги не',\n  'все',\n  'заказ не',\n  'вернул',\n  'что',\n  'получила',\n  'спасибо',\n  'не получила',\n  'денег',\n  'ждала',\n  'быстро',\n  'как',\n  'рекомендую',\n  'соответствует',\n  'пришло',\n  'доставка',\n  'размер',\n  'открыла',\n  'продавца',\n  'открыла спор',\n  'нет']}"},"metadata":{}}],"execution_count":33},{"cell_type":"code","source":"PROMPT_EXAMPLES = {\n    'обувь': [\n        \"1. слишком долгая доставка, пахнут резиной\",\n        \"2. маленькие. когда одеваешь рисунка почти нет. белая подошва.\"\n    ],\n    'одежда': [\n        \"1. цвет черный а не темно синий , обидно. шапка хорошая.\"\n        \"2. на 2 размера меньше пришел , плохо прошит , полоски стерлись на следующий день , синтетик и не теплый\",\n        \"3. заказали 14.10.2017 , получили 25.10.2017 \\n\\nна мой размер 42, широкий как мешок. надо было все таки размер  s заказать. \\n\\nпо поводу качества хороший пуховик. \\n\\nмех натуральный , съемный. \\n\\nбуду продавать .\",\n        \"4. футболка хорошего качества,но футболка не как для девушек и женщин,а как на мужчину. она очень свободная. на свой м, заказала л. теперь не знаю что делать,ибо она мне велика, даже моему папе она полезет.\",\n        \"5. рисунок не очень чёткий, а ткань прозрачная, видно нижнее бельё\"\n    ],\n    'посуда': [\n        \"1. для тех, кто пьёт напитки литрами и не хочет постоянно отвлекаться на то, чтобы их делать.\",\n        \"2. вздумалось мне заказать на алиэкспресс стальную мисочку для лапши объёмом 1 000 мл. и вот заказ прибыл. нужно доставать и проверять.\"\n    ],\n    'текстиль': [\n        \"1. приятная, нежная ткань. хороший комплект. только цвет не такой сочный, как на картинке.\",\n        \"2. мое спасение! для ёрзающих во сне)))\",\n        \"3. теплый велюровый комплект постельного белья + дополнительные наволочки.\"\n    ],\n    'товары для детей': [\n        \"1. шапку покупала ребёнку из за пампона (он чёрный)так вот он совсем не держится на шапке!!!продавцу написала об этом но он игнорит!\",\n        \"2. для ребенка старше года бесполезная. для детей помладше или тех, что спят как статуи, возможно, сработает.\"\n    ],\n    'украшения и аксессуары': [\n        \"1. фигня, нитки торчат, хотела носить как пояс-баска, размер оказался огромный\",\n        \"2. эти серьги я покупала примерно в начале 2022 года. они потерялись, не отслеживались на территории рф - я была вынуждена открыть диспут и получить деньги обратно. \",\n        \"3. самые классные цепочки\"\n    ],\n    'электроника': [\n        \"1. так себе прибор для путешествий\",\n        \"2. недорогой спидометр, работает нормально\",\n        \"3. купил светодиодную лампу, прошло три дня, очень хорошо светит когда сидишь за столом,но иногда лампа перегревается но все норм или сидишь за компьютером, думаю ещё купить лампу другу на день рождение и себе вторую лампу, всем доволен, всем рекомендую\"\n    ],\n    'нет товара': [\n        \"1. все отлично!!!\",\n        \"2. доставка до спб 35 дней.\",\n        \"3. по началу всё отслеживалось, но в конце выяснилось, что пришло в балашиху, а заказывала в саратов! ждала, но заказ так и не пришёл, защита закончилась\",\n        \"4. заказ так и не пришёл, открыла спор, продавец его не принял, просил закрыть спор и подождать, пришлось привлекать алиэкспресс, возврат денег одобрили, деньги пришли.\",\n    ]\n}\n\n# --- 2) Prompt templates (Russian) ---\nGEN_SYSTEM = (\n    \"Ты генерируешь реалистичные отзывы для маркетплейса на русском языке. \"\n    \"Следуй классу и качеству формулировок корпуса. Без брендов, без ссылок. \"\n    \"Разнообразь стиль (полож./нейтр./негат.), избегай повторов. \"\n    \"Выводи строго JSONL: по одному объекту на строку. \"\n    \"Каждый объект: {\\\"text\\\": \\\"<отзыв без переносов>\\\", \\\"label\\\": \\\"<класс>\\\"}. \"\n    \"Не используй фигурные скобки внутри текста, без markdown и подсказок.\"\n    \"Примеры реальных отзывов:\"\n    )\n\ndef make_gen_prompt(category: str, n_items: int, hints: list[str]) -> str:\n    # Compose concise hints (up to ~12 tokens/phrases)\n    sampled = \", \".join(random.sample(hints, k=min(12, max(3, len(hints))))) if hints else \"\"\n    user = (\n        f\"Сгенерируй {n_items} реалистичных отзывов категории «{category}». \"\n        \"Длина до 40 слов; варьируй стиль (положительный/нейтральный/негативный). \"\n        \"Если категория «нет товара», делай отзывы про доставку/продавца/деньги без упоминания конкретного товара. \"\n        f\"Подсказки корпуса: {sampled}\\n\"\n        \"Верни строго JSONL (одна строка — один объект) вида:\\n\"\n        \"{\\\"text\\\":\\\"...\\\", \\\"label\\\":\\\"\" + category + \"\\\"}\"\n    )\n    messages = [\n        {\"role\": \"system\", \"content\": GEN_SYSTEM + '\\n'.join(PROMPT_EXAMPLES[category])},\n        {\"role\": \"user\", \"content\": user},\n    ]\n    # chat→string\n    return tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n\n# --- 3) Robust JSONL extraction ---\ndef extract_jsonl_objects(text: str):\n    # Strip code fences if any\n    text = re.sub(r\"```(?:json)?\\s*|\\s*```\", \"\", text, flags=re.I)\n    lines = [ln.strip() for ln in text.splitlines() if ln.strip()]\n    objs = []\n    for ln in lines:\n        # quick filter: looks like a JSON object\n        if not (ln.startswith(\"{\") and ln.endswith(\"}\")):\n            continue\n        try:\n            obj = json.loads(ln)\n            if isinstance(obj, dict) and \"text\" in obj and \"label\" in obj:\n                objs.append(obj)\n        except Exception:\n            continue\n    return objs\n\n# --- 4) Batched generation core ---\ndef generate_batch(prompts: list[str],\n                   max_input_tokens=1000,\n                   max_new_tokens=1500,\n                   do_sample=True,\n                   temperature=0.8,\n                   top_p=0.9,\n                   repetition_penalty=1.05):\n    enc = tokenizer(\n        prompts, return_tensors=\"pt\",\n        padding=True, truncation=True, max_length=max_input_tokens\n    ).to(model.device)\n\n    with torch.inference_mode():\n        gen = model.generate(\n            **enc,\n            max_new_tokens=max_new_tokens,\n            do_sample=do_sample,\n            temperature=temperature,\n            top_p=top_p,\n            repetition_penalty=repetition_penalty,\n            eos_token_id=tokenizer.eos_token_id,\n            pad_token_id=tokenizer.pad_token_id,\n            use_cache=True,\n        )\n\n    # Slice new tokens only\n    input_lens = enc[\"attention_mask\"].sum(dim=1)\n    new_tokens = [out_ids[in_len:] for out_ids, in_len in zip(gen, input_lens)]\n    # Pad & decode\n    padded = pad_sequence(new_tokens, batch_first=True, padding_value=tokenizer.pad_token_id)\n    out_texts = tokenizer.batch_decode(padded, skip_special_tokens=True)\n    return out_texts\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-15T10:59:17.012176Z","iopub.execute_input":"2025-09-15T10:59:17.012839Z","iopub.status.idle":"2025-09-15T10:59:17.024870Z","shell.execute_reply.started":"2025-09-15T10:59:17.012816Z","shell.execute_reply":"2025-09-15T10:59:17.024339Z"}},"outputs":[],"execution_count":77},{"cell_type":"code","source":"prompts = []\nprompts.append(make_gen_prompt(category='электроника', n_items=10, hints=HINTS.get('электроника', [])))\nprompts","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-15T10:01:17.471302Z","iopub.execute_input":"2025-09-15T10:01:17.471752Z","iopub.status.idle":"2025-09-15T10:01:17.476620Z","shell.execute_reply.started":"2025-09-15T10:01:17.471732Z","shell.execute_reply":"2025-09-15T10:01:17.475967Z"}},"outputs":[{"execution_count":66,"output_type":"execute_result","data":{"text/plain":"['<|im_start|>system\\nТы генерируешь реалистичные отзывы для маркетплейса на русском языке. Следуй классу и качеству формулировок корпуса. Без брендов, без ссылок. Разнообразь стиль (полож./нейтр./негат.), избегай повторов. Выводи строго JSONL: по одному объекту на строку. Каждый объект: {\"text\": \"<отзыв без переносов>\", \"label\": \"<класс>\"}. Не используй фигурные скобки внутри текста, без markdown и подсказок.Примеры реальных отзывов:1. супер прибор для путешествий\\n2. недорогой спидометр, работает нормально\\n3. купил светодиодную лампу, прошло три дня, очень хорошо светит когда сидишь за столом,но иногда лампа перегревается но все норм или сидишь за компьютером, думаю ещё купить лампу другу на день рождение и себе вторую лампу, всем доволен, всем рекомендую<|im_end|>\\n<|im_start|>user\\nСгенерируй 10 реалистичных отзывов категории «электроника». Длина до 80 слов; варьируй стиль (положительный/нейтральный/негативный). Если категория «нет товара», делай отзывы про доставку/продавца/деньги без упоминания конкретного товара. Подсказки корпуса: \\nВерни строго JSONL (одна строка — один объект) вида:\\n{\"text\":\"...\", \"label\":\"электроника\"}<|im_end|>\\n<|im_start|>assistant\\n']"},"metadata":{}}],"execution_count":66},{"cell_type":"code","source":"outs = generate_batch(prompts)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-15T10:01:21.153319Z","iopub.execute_input":"2025-09-15T10:01:21.154031Z","iopub.status.idle":"2025-09-15T10:02:02.010000Z","shell.execute_reply.started":"2025-09-15T10:01:21.154005Z","shell.execute_reply":"2025-09-15T10:02:02.009387Z"}},"outputs":[],"execution_count":67},{"cell_type":"code","source":"outs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-15T10:02:02.011259Z","iopub.execute_input":"2025-09-15T10:02:02.011540Z","iopub.status.idle":"2025-09-15T10:02:02.016301Z","shell.execute_reply.started":"2025-09-15T10:02:02.011516Z","shell.execute_reply":"2025-09-15T10:02:02.015748Z"}},"outputs":[{"execution_count":68,"output_type":"execute_result","data":{"text/plain":"['```jsonl\\n{\"text\":\"У меня появился новый смартфон, и он превзошел все мои ожидания. Качество камеры просто потрясающее, а аккумулятор держит заряд целый день. Очень доволен покупкой.\", \"label\":\"электроника\"}\\n{\"text\":\"Приобрел ноутбук для работы и учебы. Он работает стабильно, но немного шумит при нагрузке. В целом, хорошая покупка для тех, кто ищет универсальное устройство.\", \"label\":\"электроника\"}\\n{\"text\":\"Этот Bluetooth-динамик отлично звучит, но батарея разряжается слишком быстро. Надеюсь, это временное явление, так как качество звука действительно впечатляет.\", \"label\":\"электроника\"}\\n{\"text\":\"Купил умные часы, они удобны в использовании, но периодически зависают. Надеюсь, обновление прошивки решит проблему.\", \"label\":\"электроника\"}\\n{\"text\":\"Светильник с LED-технологией светит ярко, но потребляет много электроэнергии. Для экономии стоит рассмотреть другие варианты.\", \"label\":\"электроника\"}\\n{\"text\":\"Приобрел умные колонки, которые стали центром моей домашней развлекательной системы. Звук отличный, но управление через голос не всегда понимает команды.\", \"label\":\"электроника\"}\\n{\"text\":\"Доставка электроники была задержана на неделю, хотя обещали быстрое обслуживание. Обратился в службу поддержки, и проблема была решена оперативно.\", \"label\":\"доставка\"}\\n{\"text\":\"Продавец был очень любезен и помог выбрать подходящую модель. Рекомендую его для покупок электроники.\", \"label\":\"продавец\"}\\n{\"text\":\"Не получил деньги за возврат электроники, так как продавец отказался принимать товар. Пришлось обращаться в банк для возврата средств.\", \"label\":\"деньги\"}\\n{\"text\":\"Приобрел умные наушники с отличным звуком, но через пару недель они перестали работать. Вернул товар, но был недоволен медленным процессом возврата.\", \"label\":\"электроника\"}\\n```']"},"metadata":{}}],"execution_count":68},{"cell_type":"code","source":"\n# --- 5) Light QA filters for realism ---\nRX_CYR = re.compile(r\"[А-Яа-яЁё]\")\ndef qa_keep(obj: dict, category: str):\n    txt = obj.get(\"text\",\"\").strip()\n    lbl = str(obj.get(\"label\",\"\")).strip().lower()\n    if lbl != category:\n        return False\n    # one line, reasonable length, Russian chars present\n    if (\"\\n\" in txt) or (len(txt.split()) < 12) or (len(txt.split()) > 90):\n        return False\n    if RX_CYR.search(txt) is None:\n        return False\n    # avoid trivial boilerplate\n    if len(set(txt.lower().split())) < 8:\n        return False\n    return True\n\n# --- 6) Driver: generate N per class ---\ndef generate_synthetics(df, target_per_class=250,\n                        prompts_per_call=2,\n                        items_per_prompt=20):\n    rows = []\n    seen = set()  # to dedupe by text\n    for category in CLASSES:\n        needed = target_per_class\n        pbar = tqdm(total=needed, desc=f\"Gen {category}\")\n        while needed > 0:\n            # Build a small batch of prompts\n            prompts = []\n            for _ in range(prompts_per_call):\n                k = min(items_per_prompt, needed)\n                prompts.append(make_gen_prompt(category, n_items=k, hints=HINTS.get(category, [])))\n            # Generate\n            outs = generate_batch(prompts)\n            # Parse & collect\n            got = 0\n            for out in outs:\n                objs = extract_jsonl_objects(out)\n                for obj in objs:\n                    if qa_keep(obj, category):\n                        t = obj[\"text\"].strip()\n                        if t not in seen:\n                            rows.append({\"text\": t, \"label\": category, \"provenance\": \"llm_gen\"})\n                            seen.add(t)\n                            got += 1\n                            pbar.update(1)\n                            needed -= 1\n                            if needed <= 0:\n                                break\n                if needed <= 0:\n                    break\n            # Small GC to keep mem tidy on Kaggle\n            gc.collect()\n            if torch.cuda.is_available():\n                torch.cuda.empty_cache()\n        pbar.close()\n    return pd.DataFrame(rows, columns=[\"text\",\"label\",\"provenance\"])\n\n# --- 7) Run generation ---\ndf_synth = generate_synthetics(df_train, target_per_class=50,\n                               prompts_per_call=2,   # try 2–4 depending on VRAM\n                               items_per_prompt=5)  # 20 JSON objects per prompt\nprint(df_synth.head(), \"\\nCounts:\\n\", df_synth['label'].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-15T10:59:32.478633Z","iopub.execute_input":"2025-09-15T10:59:32.478902Z","iopub.status.idle":"2025-09-15T13:26:20.154288Z","shell.execute_reply.started":"2025-09-15T10:59:32.478881Z","shell.execute_reply":"2025-09-15T13:26:20.153653Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Gen обувь:   0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9796b55a940c469f8b8914e7cc33e33d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Gen одежда:   0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"791357e297784f98b261503169982161"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Gen посуда:   0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e098b7cf5de347149671558d2ca09dd8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Gen текстиль:   0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22513bb008614b749ccff415bea1da5b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Gen товары для детей:   0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e36a0f90842405a86e4bf9cea0c6197"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Gen украшения и аксессуары:   0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7944d6e98aec4892a8a13d230cfa900f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Gen электроника:   0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f491b678399a4a2b93a43d1523ff8094"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Gen нет товара:   0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dec2dc3e86154ea6868bd965b2e35807"}},"metadata":{}},{"name":"stdout","text":"                                                text  label provenance\n0  Моя первая покупка у этого продавца, и я остал...  обувь    llm_gen\n1  Получил заказ быстро, но обувь маломерит на од...  обувь    llm_gen\n2  Обувь отлично сидит по размеру, удобная и стил...  обувь    llm_gen\n3  На фото обувь выглядит лучше, чем в реальности...  обувь    llm_gen\n4  Пришла обувь в целости и сохранности, но мне о...  обувь    llm_gen \nCounts:\n label\nобувь                     50\nодежда                    50\nпосуда                    50\nтекстиль                  50\nтовары для детей          50\nукрашения и аксессуары    50\nэлектроника               50\nнет товара                50\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":78},{"cell_type":"code","source":"df_synth.to_parquet('synthetic_data.parquet')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-15T13:26:20.155385Z","iopub.execute_input":"2025-09-15T13:26:20.155580Z","iopub.status.idle":"2025-09-15T13:26:20.236822Z","shell.execute_reply.started":"2025-09-15T13:26:20.155565Z","shell.execute_reply":"2025-09-15T13:26:20.236159Z"}},"outputs":[],"execution_count":79},{"cell_type":"code","source":"df_synth[df_synth['label'] == 'товары для детей']['text'].values","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-15T13:50:29.303143Z","iopub.execute_input":"2025-09-15T13:50:29.303443Z","iopub.status.idle":"2025-09-15T13:50:29.310366Z","shell.execute_reply.started":"2025-09-15T13:50:29.303420Z","shell.execute_reply":"2025-09-15T13:50:29.309737Z"}},"outputs":[{"execution_count":83,"output_type":"execute_result","data":{"text/plain":"array(['Очень довольны покупкой! Шапка идеально подходит по размеру, держится на голове ребёнка без проблем. Рекомендую!',\n       'Нейтрально. Покупали комбинезон для малыша. Подходит по возрасту, но хотелось бы более долговечный материал.',\n       'Разочарован покупкой. Несмотря на заявленный вес, кресло для автокресла оказалось слишком легким и неустойчивым. Не рекомендую.',\n       'Приобрели мягкую игрушку для годовалого сына. Вес и размер соответствуют описанию, но ребенок быстро потерял интерес.',\n       'Купили новый весовой набор для измерения роста и веса. Все отлично работает, точность высокая.',\n       'Ребёнок очень любит новую книжку с интерактивными элементами. Но срок службы аккумулятора оказался коротким.',\n       'Покупка детского стульчика для кормления оказалась разочарованием. Он неустойчивый и легко опрокидывается.',\n       'Шапка отлично держится на голове моего малыша! Материал приятный на ощупь и теплый. Рекомендую!',\n       'Коляски этого бренда удобны для наших размеров (вес 8 кг, рост 75 см), но нужно быть готовым к частым ремонтом.',\n       'Игрушка понравилась ребенку, но быстро потеряла свою привлекательность после нескольких дней игры. Нейтрально.',\n       'Пеленки удобные, но пришлось вернуть из-за несоответствия размеров (ребенок 3 месяца, вес 4 кг).',\n       'Набор развивающих игрушек для годовалого сына оказался слишком сложным. Сначала нужно разобраться самим.',\n       'Купили бутылочку для новорожденного, но она постоянно протекает. Продавец ответил, что это нормально.',\n       'Заказанный товар не соответствует описанию. Пришлось вернуть и купить у другого продавца.',\n       'Шапка для малыша оказалась идеальной! Мягкая, удобная и отлично сидит на голове. Ребёнок в восторге!',\n       'Купили для ребёнка кресло-балансир. Рост 120 см - идеально подходит. Ребёнок быстро привык и теперь часами проводит время на нём.',\n       'Покупали весы для контроля веса ребёнка. Очень точные, но дороговато. Пока довольны, но нужно было подумать перед покупкой.',\n       'Ростомер для дома установили недавно. Удобно следить за ростом ребёнка, но иногда показывает неточные значения.',\n       'Наконец-то нашел подходящую обувь для сына! Размер идеально подходит, и он чувствует себя комфортно. Рекомендую!',\n       'Покупал штанишки для девочки, но они оказались слишком тяжелыми для ее активности. Пожалею о покупке.',\n       'Качественная игрушка для малыша. Уже неделю не вылезает из рук, и это здорово развивает его моторику. Отличный выбор!',\n       'Купили велосипед для ребенка, но он оказался слишком тяжелым для него. Вернули продавцу, так как не подошел.',\n       'Шапка для ребёнка идеально села по размеру! Легкая и приятная на ощупь.',\n       'Новая кроватка для малыша понравилась своей прочностью, но ребёнок пока не оценил.',\n       'Детский стульчик для кормления оказался слишком тяжёлым для нашей квартиры. Покупкой не доволен.',\n       'Наконец-то нашла подходящий набор для развития мелкой моторики у малыша. Ребёнок в восторге!',\n       'Штаны для малыша идеально сидят по весу и росту, но мой сын вырос через неделю. Понадобилось замерять точно.',\n       'Детский матрас оказался слишком твердым для моего ребёнка. Теперь ищу более мягкую модель.',\n       'Покупка конструктора для двухлетки была успешной. Он с удовольствием собирал простые модели, но быстро потерял интерес.',\n       'Шапка для ребёнка идеально сидит! Материал приятный на ощупь и хорошо держит форму.',\n       'Покупали бутылочку для малыша, ростом 9 месяцев. Подошла отлично, но ребенок еще не может её держать самостоятельно.',\n       'Набор весов для младенцев точный, но цена завышена. Учитывая вес и возраст ребенка, можно найти лучше.',\n       'Шапка для малыша оказалась идеальной! Прекрасно сидит, удобная и теплая. Ребёнок в восторге!',\n       'Покупал комбинезон для сына. Размер подошёл, но качество ткани вызывает сомнения. Будем надеяться, что прослужит долго.',\n       'Накупили игрушек для двухлетнего ребёнка. Понравились яркие цвета и безопасность материалов. Но некоторые детали легко отваливаются.',\n       'Велосипед для девочки подошёл по размеру, но педали слишком большие для её ножек. Надо будет подумать о замене.',\n       'Мобиль для детской кроватки прекрасно выполнил свою функцию. Ребёнок спокойно засыпает под его звуки.',\n       'Покупка детского стола оказалась ошибочной. Материал не такой прочный, как на фото. Вернули деньги быстро.',\n       'Для годовалого ребёнка купили развивающую игрушку. Она оказалась слишком сложной для него. Вернули в магазин.',\n       'Купили детский матрасик. Удобный и поддерживающий, но стоимость выше, чем в других магазинах. Возможно, стоит поискать аналоги.',\n       'Покупали мягкую игрушку, но она развалилась через месяц использования. Вернули деньги, но это разочарование.',\n       'Купили детскую мебель, но она оказалась не такой прочной, как ожидали. Попробуем вернуть и выбрать другой вариант.',\n       'Игрушка для двухлетнего ребёнка понравилась. Яркая, интересная, но некоторые детали могут быть опасны для грызения.',\n       'Шапка для малыша очень понравилась! Мягкая и теплая, отлично держится на голове.',\n       'Купили развивающий кубик ребенку, но он быстро потерял интерес. Возможно, не подходит для активных детей.',\n       'Ребенок любит играть с мягкой игрушкой, но через неделю она развалилась. Качество оставляет желать лучшего.',\n       'Купили этот коврик для малыша - он очень прочный и удобный. Ребёнок уже ползает по нему с удовольствием.',\n       'Покупали бутылочку для новорожденного. Все отлично, кроме того, что она немного тяжелая для малыша. Но это мелочь.',\n       'Ожидали большего от этого ходунка - ребенок даже не пытался вставать на ножки, когда его поставили. Пожалеем потраченные деньги.',\n       'Купили этот стульчик для кормления - ребенок любит его, и мы с мужем довольны удобством использования.'],\n      dtype=object)"},"metadata":{}}],"execution_count":83},{"cell_type":"code","source":"df_synth[df_synth['label'] == 'одежда']['text'].values","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-15T10:36:08.493565Z","iopub.execute_input":"2025-09-15T10:36:08.494176Z","iopub.status.idle":"2025-09-15T10:36:08.499594Z","shell.execute_reply.started":"2025-09-15T10:36:08.494153Z","shell.execute_reply":"2025-09-15T10:36:08.498964Z"}},"outputs":[{"execution_count":74,"output_type":"execute_result","data":{"text/plain":"array(['Недавно заказала платье, но оно пришло с дефектом - одна нить вылезла. Обидно, так как продавец уверял в высоком качестве. Платье какое-то скромное, не соответствует описанию. Вернула и жду возврата денег.',\n       'Футболка идеально соответствует описанию: качество отличное, сшита аккуратно, цвет как на фото. Рекомендую!'],\n      dtype=object)"},"metadata":{}}],"execution_count":74},{"cell_type":"code","source":"print(\"hf_device_map:\", getattr(model, \"hf_device_map\", \"n/a\"))\ntry:\n    from accelerate import cpu_offload\nexcept Exception:\n    pass\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-15T09:01:52.168216Z","iopub.execute_input":"2025-09-15T09:01:52.169169Z","iopub.status.idle":"2025-09-15T09:01:52.173182Z","shell.execute_reply.started":"2025-09-15T09:01:52.169142Z","shell.execute_reply":"2025-09-15T09:01:52.172592Z"}},"outputs":[{"name":"stdout","text":"hf_device_map: {'model.embed_tokens': 0, 'model.layers.0': 0, 'model.layers.1': 0, 'model.layers.2': 0, 'model.layers.3': 0, 'model.layers.4': 0, 'model.layers.5': 0, 'model.layers.6': 0, 'model.layers.7': 1, 'model.layers.8': 1, 'model.layers.9': 1, 'model.layers.10': 1, 'model.layers.11': 1, 'model.layers.12': 1, 'model.layers.13': 1, 'model.layers.14': 1, 'model.layers.15': 1, 'model.layers.16': 1, 'model.layers.17': 1, 'model.layers.18': 1, 'model.layers.19': 1, 'model.layers.20': 1, 'model.layers.21': 1, 'model.layers.22': 1, 'model.layers.23': 1, 'model.layers.24': 1, 'model.layers.25': 1, 'model.layers.26': 1, 'model.layers.27': 1, 'model.norm': 1, 'model.rotary_emb': 1, 'lm_head': 1}\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"sum_cpu = sum(1 for _,p in model.named_parameters() if p.device.type != \"cuda\")\nprint(\"Layers on CPU:\", sum_cpu)  # should be 0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-15T08:41:44.185760Z","iopub.execute_input":"2025-09-15T08:41:44.186567Z","iopub.status.idle":"2025-09-15T08:41:44.192989Z","shell.execute_reply.started":"2025-09-15T08:41:44.186531Z","shell.execute_reply":"2025-09-15T08:41:44.192152Z"}},"outputs":[{"name":"stdout","text":"Layers on CPU: 0\n","output_type":"stream"}],"execution_count":37},{"cell_type":"markdown","source":"## Создаем аугментации","metadata":{}},{"cell_type":"code","source":"!pip install ruwordnet nltk pymorphy3","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-16T06:27:10.628524Z","iopub.execute_input":"2025-09-16T06:27:10.629114Z","iopub.status.idle":"2025-09-16T06:27:13.610817Z","shell.execute_reply.started":"2025-09-16T06:27:10.629086Z","shell.execute_reply":"2025-09-16T06:27:13.610132Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: ruwordnet in /usr/local/lib/python3.11/dist-packages (0.0.6)\nRequirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\nRequirement already satisfied: pymorphy3 in /usr/local/lib/python3.11/dist-packages (2.0.4)\nRequirement already satisfied: sqlalchemy<2.0 in /usr/local/lib/python3.11/dist-packages (from ruwordnet) (1.4.54)\nRequirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.1)\nRequirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.1)\nRequirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\nRequirement already satisfied: dawg2-python>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from pymorphy3) (0.9.0)\nRequirement already satisfied: pymorphy3-dicts-ru in /usr/local/lib/python3.11/dist-packages (from pymorphy3) (2.4.417150.4580142)\nRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<2.0->ruwordnet) (3.2.3)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"!ruwordnet download","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-16T06:27:13.611963Z","iopub.execute_input":"2025-09-16T06:27:13.612233Z","iopub.status.idle":"2025-09-16T06:27:14.709634Z","shell.execute_reply.started":"2025-09-16T06:27:13.612209Z","shell.execute_reply":"2025-09-16T06:27:14.708938Z"}},"outputs":[{"name":"stdout","text":"downloading a ruwordnet model from https://github.com/avidale/python-ruwordnet/releases/download/0.0.4/ruwordnet-2021.db\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import pandas as pd\n\ndf_train_synth = pd.read_parquet('/kaggle/input/train-predictions/synthetic_data.parquet')\ndf_train_with_labels = pd.read_parquet('/kaggle/input/train-predictions/train_with_labels.parquet')\ndf_train_full = pd.concat([df_train_with_labels, df_train_synth])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-16T06:29:46.636397Z","iopub.execute_input":"2025-09-16T06:29:46.637081Z","iopub.status.idle":"2025-09-16T06:29:46.805567Z","shell.execute_reply.started":"2025-09-16T06:29:46.637054Z","shell.execute_reply":"2025-09-16T06:29:46.805008Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# === Text Augmentation Toolkit (RU/EN friendly) ===\nimport re, random, math\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nfrom ruwordnet import RuWordNet\nfrom pymorphy3 import MorphAnalyzer\nimport nltk\nfrom nltk.corpus import wordnet as wn\n\n\n_ = wn.ensure_loaded()\nmorph = MorphAnalyzer()\nrwn = RuWordNet()\n\nrandom.seed(42)\nnp.random.seed(42)\n\n# --- Alphabets for char noise ---\nRU_LOWER = list(\"абвгдеёжзийклмнопрстуфхцчшщъыьэюя\")\nRU_UPPER = [c.upper() for c in RU_LOWER]\nEN_LOWER = list(\"abcdefghijklmnopqrstuvwxyz\")\nEN_UPPER = [c.upper() for c in EN_LOWER]\n\ndef _rand_other(char_list, cur):\n    if len(char_list) == 1: return cur\n    c = cur\n    while c == cur:\n        c = random.choice(char_list)\n    return c\n\ndef char_noise(text: str, p_char: float = 0.02) -> str:\n    \"\"\"Replace each RU/EN letter with a random same-script, same-case letter with prob p_char.\"\"\"\n    out = []\n    for ch in text:\n        r = random.random()\n        if r >= p_char:\n            out.append(ch); continue\n        if ch in RU_LOWER:\n            out.append(_rand_other(RU_LOWER, ch))\n        elif ch in RU_UPPER:\n            out.append(_rand_other(RU_UPPER, ch))\n        elif ch in EN_LOWER:\n            out.append(_rand_other(EN_LOWER, ch))\n        elif ch in EN_UPPER:\n            out.append(_rand_other(EN_UPPER, ch))\n        else:\n            out.append(ch)  # don’t touch digits/punct/space\n    return \"\".join(out)\n\nRX_CYR = re.compile(r\"[А-Яа-яЁё]\")\n\ndef _transfer_case(src: str, dst: str) -> str:\n    if src.isupper(): return dst.upper()\n    if src.istitle(): return dst.capitalize()\n    return dst\n\ndef ru_synonyms(word: str, max_k: int = 5) -> list[str]:\n    \"\"\"Russian synonyms via RuWordNet (if available). Returns lemmas; tries to inflect back.\"\"\"\n    if rwn is None or morph is None: return []\n    p = morph.parse(word)[0]\n    lemma = p.normal_form\n    syns = set()\n    try:\n        # Collect lemmas from all synsets where lemma appears\n        for ss in rwn.get_synsets(lemma):\n            for lit in ss.literals:\n                cand = lit.text.lower()\n                if cand != lemma:\n                    syns.add(cand)\n    except Exception:\n        return []\n    syns = list(syns)[:max_k]\n    # try to inflect to the same grammemes\n    out = []\n    for s in syns:\n        sp = morph.parse(s)[0]\n        # attempt to match grammemes intersection\n        gramm = {g for g in p.tag.grammemes if g in sp.tag.grammemes}\n        try:\n            inf = sp.inflect(gramm) if gramm else None\n            out.append((inf.word if inf else s))\n        except Exception:\n            out.append(s)\n    return out\n\ndef en_synonyms(word: str, max_k: int = 5) -> list[str]:\n    if wn is None: return []\n    wlow = word.lower()\n    syns = set()\n    try:\n        for ss in wn.synsets(wlow, lang='eng'):\n            for l in ss.lemmas(lang='eng'):\n                cand = l.name().replace(\"_\",\" \").lower()\n                if cand != wlow:\n                    syns.add(cand)\n    except Exception:\n        return []\n    return list(syns)[:max_k]\n\ndef get_synonyms(word: str) -> list[str]:\n    \"\"\"Auto-detect RU/EN and fetch synonyms; may return [].\"\"\"\n    if RX_CYR.search(word):\n        return ru_synonyms(word)\n    else:\n        return en_synonyms(word)\n\nWORD_RX = re.compile(r\"[A-Za-zА-Яа-яЁё]+\")\n\ndef synonym_replace(text: str, p_word: float = 0.12) -> str:\n    \"\"\"\n    With prob p_word per token, replace by a synonym (if available).\n    Keeps punctuation/spacing; preserves case shape of the original token.\n    \"\"\"\n    tokens = re.findall(r\"\\w+|[^\\w\\s]+|\\s+\", text, flags=re.UNICODE)\n    out = []\n    for tok in tokens:\n        if WORD_RX.fullmatch(tok) and random.random() < p_word:\n            syns = get_synonyms(tok)\n            syns = [s for s in syns if s.lower() != tok.lower()]\n            if syns:\n                repl = random.choice(syns)\n                out.append(_transfer_case(tok, repl))\n                continue\n        out.append(tok)\n    return \"\".join(out)\n\ndef swap_adjacent_words(text: str, p_swap: float = 0.08) -> str:\n    \"\"\"\n    Swap adjacent word tokens with probability p_swap (non-overlapping).\n    Non-word tokens (punct/space) keep their positions relative to words.\n    \"\"\"\n    # Split into words and separators, then operate on word indices\n    parts = re.findall(r\"[A-Za-zА-Яа-яЁё]+|[^A-Za-zА-Яа-яЁё]+\", text)\n    # Identify word indices\n    idx = [i for i, p in enumerate(parts) if WORD_RX.fullmatch(p)]\n    i = 0\n    while i < len(idx) - 1:\n        if random.random() < p_swap:\n            a, b = idx[i], idx[i+1]\n            parts[a], parts[b] = parts[b], parts[a]\n            i += 2  # skip next to avoid overlapping swaps\n        else:\n            i += 1\n    return \"\".join(parts)\n\n# --- Top-level driver to build augmented DataFrame ---\ndef augment_dataframe(df: pd.DataFrame,\n                      p_char: float = 0.03,\n                      p_syn: float = 0.2,\n                      p_swap: float = 0.2,\n                      which=(\"char_noise\",\"synonym\",\"swap\"),\n                      keep_original=True,\n                      repeat=1) -> pd.DataFrame:\n    \"\"\"\n    Apply selected augmentations to each row of df[['text','label']].\n    Returns a new dataframe with columns: text, label, augmentation.\n    \"\"\"\n    assert {'text','label'}.issubset(df.columns)\n    rows = []\n    for i, (txt, lab) in tqdm(enumerate(df[['text','label']].itertuples(index=False))):\n        for _ in range(repeat):\n            text = \"\" if pd.isna(txt) else str(txt)\n            if \"swap\" in which:\n                text = swap_adjacent_words(text, p_swap)\n            if \"synonym\" in which:\n                text = synonym_replace(text, p_syn)\n            if \"char_noise\" in which:\n                text = char_noise(text, p_char)\n            rows.append({\"text\": text, \"label\": lab, \"augmentation\":\"true\"})\n        if keep_original:\n            rows.append({\"text\": txt, \"label\": lab, \"augmentation\":\"false\"})\n    return pd.DataFrame(rows, columns=[\"text\",\"label\",\"augmentation\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-16T06:30:51.208531Z","iopub.execute_input":"2025-09-16T06:30:51.209358Z","iopub.status.idle":"2025-09-16T06:30:51.313780Z","shell.execute_reply.started":"2025-09-16T06:30:51.209321Z","shell.execute_reply":"2025-09-16T06:30:51.313057Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"df_train_full = df_train_full[['text', 'label']]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-16T06:31:24.270540Z","iopub.execute_input":"2025-09-16T06:31:24.271155Z","iopub.status.idle":"2025-09-16T06:31:24.276261Z","shell.execute_reply.started":"2025-09-16T06:31:24.271122Z","shell.execute_reply":"2025-09-16T06:31:24.275505Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"df_augmented = augment_dataframe(df_train_full, p_char=0.03, p_syn=0.15, p_swap=0.2,\n                                 which=(\"char_noise\",\"synonym\",\"swap\"),\n                                 keep_original=True, repeat=3)\nprint(df_augmented.head())\nprint(df_augmented['augmentation'].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-16T06:31:26.964882Z","iopub.execute_input":"2025-09-16T06:31:26.965211Z","iopub.status.idle":"2025-09-16T06:31:40.569548Z","shell.execute_reply.started":"2025-09-16T06:31:26.965188Z","shell.execute_reply":"2025-09-16T06:31:40.568782Z"}},"outputs":[{"name":"stderr","text":"2218it [00:13, 163.25it/s]","output_type":"stream"},{"name":"stdout","text":"                                                text   label augmentation\n0  заказали 14.10.2017 , получили 25.10.2017 \\n\\n...  одежда         true\n1  голучили 14.10.2017 , заказали 25.10.2017 \\n\\n...  одежда         true\n2  получили 14.10.2017 , заказали 25.10.2017 \\n\\n...  одежда         true\n3  заказали 14.10.2017 , получили 25.10.2017 \\n\\n...  одежда        false\n4  футболка хорошего качества,но фугболка не как ...  одежда         true\naugmentation\ntrue     6654\nfalse    2218\nName: count, dtype: int64\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"df_augmented.head(10)['text'].values","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-16T06:32:17.902950Z","iopub.execute_input":"2025-09-16T06:32:17.903242Z","iopub.status.idle":"2025-09-16T06:32:17.908513Z","shell.execute_reply.started":"2025-09-16T06:32:17.903222Z","shell.execute_reply":"2025-09-16T06:32:17.907886Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"array(['заказали 14.10.2017 , получили 25.10.2017 \\n\\nмой на рязмер 42, широкий как мешок. надо было все таки размер  s заказать. \\n\\nпо поводу хороший качества пуховик. \\n\\nмех съемный , натуральный. \\n\\nпродавать буду .',\n       'голучили 14.10.2017 , заказали 25.10.2017 \\n\\nмой на размер 42, широкий как мешок. надо было все таки размер  s заказать. \\n\\nпо поводу качества пуховик хоьосий. \\n\\nнатуральный мех , буду. \\n\\nсъемный продавать .',\n       'получили 14.10.2017 , заказали 25.10.2017 \\n\\nна мой широкий 42, ркзмюр кщк мешок. надо все было таки s  размср заказать. \\n\\nпо поводу хороший качестоа пуховик. \\n\\nнатуральный мех , съемный. \\n\\nпродавать буду .',\n       'заказали 14.10.2017 , получили 25.10.2017 \\n\\nна мой размер 42, широкий как мешок. надо было все таки размер  s заказать. \\n\\nпо поводу качества хороший пуховик. \\n\\nмех натуральный , съемный. \\n\\nбуду продавать .',\n       'футболка хорошего качества,но фугболка не как девушек для и женщин,как а мужчину на. она очень свободная. свой на ч, ыаказала л. теперь знаю не ото делать,ибо она мне всника, моему даже папе она полезет.',\n       'аорошего футболка качества,футболка но вн как для девушек женщин и,как а на мужчину. она свободная кчень. на м свой, заназала тепера. л ёнаю не что делать,ибо она мне велика, моему даже она папе полезет.',\n       'футболка качества хорошего,но футболка не как еля девуюек и женщин,а кък на мужчину. она своблдная ожень. на свой м, заказала л. теперь не знаю делать что,ибо она велика мне, даже папе моему она нолезет.',\n       'футболка хорошего качества,но футболка не как для девушек и женщин,а как на мужчину. она очень свободная. на свой м, заказала л. теперь не знаю что делать,ибо она мне велика, даже моему папе она полезет.',\n       'все отлиьно!!!', 'все отлично!!!'], dtype=object)"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"df_augmented.to_parquet('train_augmented.parquet')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-16T06:35:08.839359Z","iopub.execute_input":"2025-09-16T06:35:08.839889Z","iopub.status.idle":"2025-09-16T06:35:08.866484Z","shell.execute_reply.started":"2025-09-16T06:35:08.839864Z","shell.execute_reply":"2025-09-16T06:35:08.865962Z"}},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"### QLoRA","metadata":{}},{"cell_type":"code","source":"!pip install -U \"transformers==4.44.2\" \"trl==0.9.6\" \"peft==0.11.1\" \"accelerate==0.33.0\" \"bitsandbytes==0.44.1\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T08:37:30.559560Z","iopub.execute_input":"2025-09-18T08:37:30.560103Z","iopub.status.idle":"2025-09-18T08:40:53.980660Z","shell.execute_reply.started":"2025-09-18T08:37:30.560083Z","shell.execute_reply":"2025-09-18T08:40:53.979510Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fe876d8acd0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/transformers/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fe876b5e910>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/transformers/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fe876b78c90>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/transformers/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fe876b5b890>: Failed to establish a new connection: [Errno -2] Name or service not known')': /simple/transformers/\u001b[0m\u001b[33m\n\u001b[0mCollecting transformers==4.44.2\n  Downloading transformers-4.44.2-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting trl==0.9.6\n  Downloading trl-0.9.6-py3-none-any.whl.metadata (12 kB)\nCollecting peft==0.11.1\n  Downloading peft-0.11.1-py3-none-any.whl.metadata (13 kB)\nCollecting accelerate==0.33.0\n  Downloading accelerate-0.33.0-py3-none-any.whl.metadata (18 kB)\nCollecting bitsandbytes==0.44.1\n  Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (0.33.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (2.32.4)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (0.5.3)\nCollecting tokenizers<0.20,>=0.19 (from transformers==4.44.2)\n  Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (4.67.1)\nRequirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from trl==0.9.6) (2.6.0+cu124)\nRequirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (from trl==0.9.6) (3.6.0)\nCollecting tyro>=0.5.11 (from trl==0.9.6)\n  Downloading tyro-0.9.31-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft==0.11.1) (7.0.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.44.2) (2025.5.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.44.2) (4.14.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.44.2) (1.1.5)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.44.2) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.44.2) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.44.2) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.44.2) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.44.2) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.44.2) (2.4.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.9.6) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.9.6) (3.1.6)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.4.0->trl==0.9.6)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.4.0->trl==0.9.6)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.4.0->trl==0.9.6)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.4.0->trl==0.9.6)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.4.0->trl==0.9.6)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.4.0->trl==0.9.6)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.4.0->trl==0.9.6)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.4.0->trl==0.9.6)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.4.0->trl==0.9.6)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.9.6) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.9.6) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.9.6) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.4.0->trl==0.9.6)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.9.6) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4.0->trl==0.9.6) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.4.0->trl==0.9.6) (1.3.0)\nRequirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.11/dist-packages (from tyro>=0.5.11->trl==0.9.6) (0.16)\nRequirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.11/dist-packages (from tyro>=0.5.11->trl==0.9.6) (14.0.0)\nCollecting shtab>=1.5.6 (from tyro>=0.5.11->trl==0.9.6)\n  Downloading shtab-1.7.2-py3-none-any.whl.metadata (7.4 kB)\nRequirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from tyro>=0.5.11->trl==0.9.6) (4.4.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets->trl==0.9.6) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets->trl==0.9.6) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets->trl==0.9.6) (2.2.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets->trl==0.9.6) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets->trl==0.9.6) (0.70.16)\nCollecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.23.2->transformers==4.44.2)\n  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.44.2) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.44.2) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.44.2) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.44.2) (2025.6.15)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->trl==0.9.6) (3.12.13)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.9.6) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.9.6) (2.19.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.4.0->trl==0.9.6) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers==4.44.2) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers==4.44.2) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers==4.44.2) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers==4.44.2) (2024.2.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->trl==0.9.6) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->trl==0.9.6) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->trl==0.9.6) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->trl==0.9.6) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->trl==0.9.6) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->trl==0.9.6) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->trl==0.9.6) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->trl==0.9.6) (6.6.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->trl==0.9.6) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->trl==0.9.6) (1.20.1)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers==4.44.2) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl==0.9.6) (0.1.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->trl==0.9.6) (1.17.0)\nDownloading transformers-4.44.2-py3-none-any.whl (9.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m116.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading trl-0.9.6-py3-none-any.whl (245 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.8/245.8 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading peft-0.11.1-py3-none-any.whl (251 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.6/251.6 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading accelerate-0.33.0-py3-none-any.whl (315 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.1/315.1 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl (122.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m91.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m101.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m86.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tyro-0.9.31-py3-none-any.whl (131 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.7/131.7 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading shtab-1.7.2-py3-none-any.whl (14 kB)\nInstalling collected packages: shtab, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, fsspec, nvidia-cusparse-cu12, nvidia-cudnn-cu12, tyro, tokenizers, nvidia-cusolver-cu12, transformers, accelerate, trl, peft, bitsandbytes\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.5.1\n    Uninstalling fsspec-2025.5.1:\n      Successfully uninstalled fsspec-2025.5.1\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.21.2\n    Uninstalling tokenizers-0.21.2:\n      Successfully uninstalled tokenizers-0.21.2\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.52.4\n    Uninstalling transformers-4.52.4:\n      Successfully uninstalled transformers-4.52.4\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 1.8.1\n    Uninstalling accelerate-1.8.1:\n      Successfully uninstalled accelerate-1.8.1\n  Attempting uninstall: peft\n    Found existing installation: peft 0.15.2\n    Uninstalling peft-0.15.2:\n      Successfully uninstalled peft-0.15.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed accelerate-0.33.0 bitsandbytes-0.44.1 fsspec-2025.3.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 peft-0.11.1 shtab-1.7.2 tokenizers-0.19.1 transformers-4.44.2 trl-0.9.6 tyro-0.9.31\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# !pip install transformers bitsandbytes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T08:40:53.982573Z","iopub.execute_input":"2025-09-18T08:40:53.982877Z","iopub.status.idle":"2025-09-18T08:40:53.986831Z","shell.execute_reply.started":"2025-09-18T08:40:53.982845Z","shell.execute_reply":"2025-09-18T08:40:53.985972Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"import transformers\n\ntransformers.__version__","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T08:40:53.987519Z","iopub.execute_input":"2025-09-18T08:40:53.987831Z","iopub.status.idle":"2025-09-18T08:40:57.679371Z","shell.execute_reply.started":"2025-09-18T08:40:53.987802Z","shell.execute_reply":"2025-09-18T08:40:57.678647Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"'4.44.2'"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"import trl\ntrl.__version__","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T08:40:57.681179Z","iopub.execute_input":"2025-09-18T08:40:57.681531Z","iopub.status.idle":"2025-09-18T08:40:57.687867Z","shell.execute_reply.started":"2025-09-18T08:40:57.681513Z","shell.execute_reply":"2025-09-18T08:40:57.687289Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"'0.9.6'"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"import pandas as pd\n\ndf_augmented = pd.read_parquet('/kaggle/input/tbank-predictions/train_augmented.parquet')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T08:42:04.986041Z","iopub.execute_input":"2025-09-18T08:42:04.986618Z","iopub.status.idle":"2025-09-18T08:42:05.117137Z","shell.execute_reply.started":"2025-09-18T08:42:04.986594Z","shell.execute_reply":"2025-09-18T08:42:05.116572Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\ndef stratified_fraction(df: pd.DataFrame, label_col: str = \"label\",\n                        frac: float = 0.5, random_state: int = 42) -> pd.DataFrame:\n    \"\"\"\n    Return a stratified subsample with size ≈ frac * len(df), preserving label fractions.\n    Ensures the total is exactly round(frac * N) via fractional rounding.\n    \"\"\"\n    assert 0 < frac < 1, \"frac must be in (0,1)\"\n    assert label_col in df.columns, f\"'{label_col}' column not found\"\n\n    counts = df[label_col].value_counts()\n    desired = counts * frac\n    target_total = int(round(len(df) * frac))\n\n    floors = np.floor(desired).astype(int)\n    remainder = target_total - floors.sum()\n\n    targets = floors.copy()\n\n    if remainder > 0:\n        # Give +1 to classes with largest fractional part\n        fractional = (desired - floors).sort_values(ascending=False)\n        for lab in fractional.index[:remainder]:\n            targets[lab] += 1\n    elif remainder < 0:\n        # Remove 1 from classes with smallest fractional part (but not below 0)\n        fractional = (desired - floors).sort_values(ascending=True)\n        removed = 0\n        for lab in fractional.index:\n            if removed == -remainder:\n                break\n            if targets[lab] > 0:\n                targets[lab] -= 1\n                removed += 1\n\n    # Sample per class\n    parts = []\n    for lab, n in targets.items():\n        if n <= 0:\n            continue\n        grp = df[df[label_col] == lab]\n        # If a class is tiny and rounding asked for more than available (shouldn't happen), clip:\n        n = min(n, len(grp))\n        parts.append(grp.sample(n=n, random_state=random_state))\n\n    df_out = pd.concat(parts, axis=0).sample(frac=1.0, random_state=random_state).reset_index(drop=True)\n\n    # Sanity checks (optional)\n    print(\"Original size:\", len(df), \"→ New size:\", len(df_out))\n    print(\"Original dist:\\n\", (df[label_col].value_counts(normalize=True)).sort_index())\n    print(\"New dist:\\n\", (df_out[label_col].value_counts(normalize=True)).sort_index())\n\n    return df_out\n\ndf_augmented = stratified_fraction(df_augmented, label_col=\"label\", frac=0.5, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T08:42:05.192601Z","iopub.execute_input":"2025-09-18T08:42:05.192881Z","iopub.status.idle":"2025-09-18T08:42:05.230810Z","shell.execute_reply.started":"2025-09-18T08:42:05.192860Z","shell.execute_reply":"2025-09-18T08:42:05.229954Z"}},"outputs":[{"name":"stdout","text":"Original size: 8872 → New size: 4436\nOriginal dist:\n label\nнет товара                0.292155\nобувь                     0.039675\nодежда                    0.532011\nпосуда                    0.023895\nтекстиль                  0.035167\nтовары для детей          0.023895\nукрашения и аксессуары    0.030658\nэлектроника               0.022543\nName: proportion, dtype: float64\nNew dist:\n label\nнет товара                0.292155\nобувь                     0.039675\nодежда                    0.532011\nпосуда                    0.023895\nтекстиль                  0.035167\nтовары для детей          0.023895\nукрашения и аксессуары    0.030658\nэлектроника               0.022543\nName: proportion, dtype: float64\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# ===================== QLoRA single-token classifier (Weighted F1) =====================\n# Requirements: transformers>=4.43, peft>=0.11, trl>=0.9, bitsandbytes>=0.43, scikit-learn\nimport os, re, json, random, gc\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, f1_score\n\nfrom transformers import (AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig,\n                          LogitsProcessor)\nfrom peft import LoraConfig, get_peft_model, TaskType\nfrom trl import SFTTrainer, SFTConfig\nfrom datasets import Dataset, DatasetDict","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T08:42:05.393244Z","iopub.execute_input":"2025-09-18T08:42:05.393502Z","iopub.status.idle":"2025-09-18T08:42:21.327258Z","shell.execute_reply.started":"2025-09-18T08:42:05.393485Z","shell.execute_reply":"2025-09-18T08:42:21.326501Z"}},"outputs":[{"name":"stderr","text":"2025-09-18 08:42:09.964624: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1758184930.138980      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1758184930.190716      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"# -------------------- Setup & constants --------------------\ntorch.manual_seed(42)\nnp.random.seed(42)\nrandom.seed(42)\ntorch.backends.cuda.matmul.allow_tf32 = True\n\nBASE_MODEL = \"t-tech/T-lite-it-1.0\"  # your T-Lite checkpoint\nCLASSES = ['обувь','одежда','посуда','текстиль','товары для детей',\n           'украшения и аксессуары','электроника','нет товара']\nIDX = {c:i for i,c in enumerate(CLASSES)}\n\n# Ensure df_augmented has the right columns\nassert {'text','label'}.issubset(df_augmented.columns), \"df_augmented must have 'text' and 'label'\"\n\n# -------------------- Train/val split (stratified) --------------------\ndf_augmented = df_augmented.sample(frac=1.0, random_state=42).reset_index(drop=True)\ntrain_df, val_df = train_test_split(\n    df_augmented[['text','label']].dropna(),\n    test_size=0.15, random_state=42, stratify=df_augmented['label']\n)\ntrain_df = train_df.reset_index(drop=True)\nval_df   = val_df.reset_index(drop=True)\n\nprint(\"Train size:\", len(train_df), \"Eval size:\", len(val_df))\nprint(\"Train class counts:\\n\", train_df['label'].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T08:42:21.328498Z","iopub.execute_input":"2025-09-18T08:42:21.329111Z","iopub.status.idle":"2025-09-18T08:42:21.704624Z","shell.execute_reply.started":"2025-09-18T08:42:21.329091Z","shell.execute_reply":"2025-09-18T08:42:21.703818Z"}},"outputs":[{"name":"stdout","text":"Train size: 3770 Eval size: 666\nTrain class counts:\n label\nодежда                    2006\nнет товара                1101\nобувь                      149\nтекстиль                   133\nукрашения и аксессуары     116\nпосуда                      90\nтовары для детей            90\nэлектроника                 85\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"!pip -q install sentencepiece","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T08:42:21.705283Z","iopub.execute_input":"2025-09-18T08:42:21.705572Z","iopub.status.idle":"2025-09-18T08:42:24.740678Z","shell.execute_reply.started":"2025-09-18T08:42:21.705553Z","shell.execute_reply":"2025-09-18T08:42:24.739875Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# -------------------- Tokenizer & label tokens --------------------\ntokenizer = AutoTokenizer.from_pretrained(BASE_MODEL, use_fast=False)\nif tokenizer.pad_token_id is None:\n    tokenizer.pad_token_id = tokenizer.eos_token_id\ntokenizer.padding_side = \"right\"  # better for decoder-only\n\n# One special token per class; model will learn to generate exactly this single token\nlabel_to_token = {c: f\"<cat_{i}>\" for i, c in enumerate(CLASSES)}\ntoken_to_label = {v: k for k, v in label_to_token.items()}\nspecials = list(label_to_token.values())\ntokenizer.add_special_tokens({\"additional_special_tokens\": specials})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T08:42:24.742632Z","iopub.execute_input":"2025-09-18T08:42:24.742868Z","iopub.status.idle":"2025-09-18T08:42:27.964833Z","shell.execute_reply.started":"2025-09-18T08:42:24.742846Z","shell.execute_reply":"2025-09-18T08:42:27.964044Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"951ed9a08e8844e9b1a3172c8f0443e2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58ee31a2c2864fa2b59b185ad5db2257"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12a3275d868d47149fbb2a756a67c900"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0243c22eeb194f698668edf45b772bb5"}},"metadata":{}},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"8"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"train_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T08:42:27.965740Z","iopub.execute_input":"2025-09-18T08:42:27.965996Z","iopub.status.idle":"2025-09-18T08:42:27.975808Z","shell.execute_reply.started":"2025-09-18T08:42:27.965971Z","shell.execute_reply":"2025-09-18T08:42:27.975139Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"                                                   text       label\n0     Заказ был отправлен месяц но, назад до сих пор...  нет товара\n1                  цвет совсем не такой как был заказан  нет товара\n2                                   качество на троечку  нет товара\n3     шорты пбдошли размером на м  кг 48 вес, рост 1...      одежда\n4     получить Ржидал красисую миску, но пришла она ...      посуда\n...                                                 ...         ...\n3765  товар не пишел. никакого общенияс продавцом не...  нет товара\n3766  заказ пнишел через месяц до окутска. классный ...  нет товара\n3767  ну такое. в целом неплохо. на тдоечку за ьакие...  нет товара\n3768  кяута классная. пришла без размера. заказывала...      одежда\n3769  тонкая приятеац пояс. ткань юе анатомически вы...      одежда\n\n[3770 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Заказ был отправлен месяц но, назад до сих пор...</td>\n      <td>нет товара</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>цвет совсем не такой как был заказан</td>\n      <td>нет товара</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>качество на троечку</td>\n      <td>нет товара</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>шорты пбдошли размером на м  кг 48 вес, рост 1...</td>\n      <td>одежда</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>получить Ржидал красисую миску, но пришла она ...</td>\n      <td>посуда</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3765</th>\n      <td>товар не пишел. никакого общенияс продавцом не...</td>\n      <td>нет товара</td>\n    </tr>\n    <tr>\n      <th>3766</th>\n      <td>заказ пнишел через месяц до окутска. классный ...</td>\n      <td>нет товара</td>\n    </tr>\n    <tr>\n      <th>3767</th>\n      <td>ну такое. в целом неплохо. на тдоечку за ьакие...</td>\n      <td>нет товара</td>\n    </tr>\n    <tr>\n      <th>3768</th>\n      <td>кяута классная. пришла без размера. заказывала...</td>\n      <td>одежда</td>\n    </tr>\n    <tr>\n      <th>3769</th>\n      <td>тонкая приятеац пояс. ткань юе анатомически вы...</td>\n      <td>одежда</td>\n    </tr>\n  </tbody>\n</table>\n<p>3770 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"# -------------------- Prompt & tokenization --------------------\nSYSTEM_INSTR = (\n    \"Ты — точный классификатор отзывов маркетплейса. Выбери ровно один ярлык \"\n    \"из списка. Если отзыв про доставку/продавца/деньги/спор без явного товара — метка «нет товара». \"\n    \"Отвечай только одним служебным токеном класса.\"\n)\n\ndef build_chat_prompt(text: str) -> str:\n    labels_str = \", \".join([f'{label_to_token[c]}({c})' for c in CLASSES])\n    messages = [\n        {\"role\": \"system\", \"content\": SYSTEM_INSTR},\n        {\"role\": \"user\", \"content\": f\"Отзыв:\\n{text}\\n\\nМетки: {labels_str}\"},\n    ]\n    return tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=False)\n\ndef tokenize_row(ex):\n    # Format as: [prompt][answer_token]; mask all prompt tokens, supervise only the last token\n    txt = \"\" if ex[\"text\"] is None else str(ex[\"text\"])\n    ytok = label_to_token[ex[\"label\"]]\n    prompt = build_chat_prompt(txt)\n    full   = prompt + ytok\n    enc = tokenizer(full, truncation=True, max_length=512)   # no padding here\n    L = len(enc[\"input_ids\"])\n    enc[\"labels\"] = [-100]*(L-1) + [enc[\"input_ids\"][-1]]    # 1 label per token, last is supervised\n    # ensure plain Python lists of ints (no numpy/ragged objs)\n    for k in (\"input_ids\",\"attention_mask\",\"labels\"):\n        enc[k] = list(map(int, enc[k]))\n    return enc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T08:42:27.976606Z","iopub.execute_input":"2025-09-18T08:42:27.976846Z","iopub.status.idle":"2025-09-18T08:42:27.991447Z","shell.execute_reply.started":"2025-09-18T08:42:27.976824Z","shell.execute_reply":"2025-09-18T08:42:27.990617Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"from transformers import DataCollatorForLanguageModeling\n\ntrain_df = train_df.reset_index(drop=True)\nval_df   = val_df.reset_index(drop=True)\n\ntrain_ds = Dataset.from_pandas(train_df[[\"text\",\"label\"]])\nval_ds   = Dataset.from_pandas(val_df[[\"text\",\"label\"]])\n\ntrain_tok = train_ds.map(tokenize_row, remove_columns=train_ds.column_names, desc=\"Tokenize train\")\nval_tok   = val_ds.map(tokenize_row,   remove_columns=val_ds.column_names,   desc=\"Tokenize val\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T08:42:27.992514Z","iopub.execute_input":"2025-09-18T08:42:27.992789Z","iopub.status.idle":"2025-09-18T08:42:38.606172Z","shell.execute_reply.started":"2025-09-18T08:42:27.992764Z","shell.execute_reply":"2025-09-18T08:42:38.605359Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Tokenize train:   0%|          | 0/3770 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75d53eaf0913401b84de475099b810dd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Tokenize val:   0%|          | 0/666 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"427bc8e01c2048d3b2d7beed42f83c24"}},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"ds = DatasetDict(train=train_tok, validation=val_tok)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T08:42:38.606956Z","iopub.execute_input":"2025-09-18T08:42:38.607588Z","iopub.status.idle":"2025-09-18T08:42:38.611282Z","shell.execute_reply.started":"2025-09-18T08:42:38.607567Z","shell.execute_reply":"2025-09-18T08:42:38.610540Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"# sanity: lengths match and are 1-D\ndef _check(ds, n=5):\n    for i in range(min(n, len(ds))):\n        L = len(ds[i][\"input_ids\"])\n        assert len(ds[i][\"labels\"]) == L and isinstance(ds[i][\"labels\"][-1], int)\n_check(train_tok)\n_check(val_tok)\n\n # custom collator that pads inputs AND labels together\ndef collate_fn(batch):\n     pad_id = tokenizer.pad_token_id\n     max_len = max(len(x[\"input_ids\"]) for x in batch)\n     input_ids, attn_mask, labels = [], [], []\n     for ex in batch:\n         L = len(ex[\"input_ids\"]); pad_len = max_len - L\n         input_ids.append(torch.tensor(ex[\"input_ids\"] + [pad_id]*pad_len, dtype=torch.long))\n         attn_mask.append(torch.tensor(ex[\"attention_mask\"] + [0]*pad_len, dtype=torch.long))\n         labels.append(torch.tensor(ex[\"labels\"] + [-100]*pad_len, dtype=torch.long))  # <- pad labels\n     return {\n         \"input_ids\": torch.stack(input_ids, 0),\n         \"attention_mask\": torch.stack(attn_mask, 0),\n         \"labels\": torch.stack(labels, 0),\n     }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T08:42:38.612073Z","iopub.execute_input":"2025-09-18T08:42:38.612551Z","iopub.status.idle":"2025-09-18T08:42:38.637760Z","shell.execute_reply.started":"2025-09-18T08:42:38.612526Z","shell.execute_reply":"2025-09-18T08:42:38.637058Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"!pip install -U \"triton==3.0.0\"\n   # installs a recent compatible Triton","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T08:42:38.639695Z","iopub.execute_input":"2025-09-18T08:42:38.639959Z","iopub.status.idle":"2025-09-18T08:42:52.321947Z","shell.execute_reply.started":"2025-09-18T08:42:38.639944Z","shell.execute_reply":"2025-09-18T08:42:52.321073Z"}},"outputs":[{"name":"stdout","text":"Collecting triton==3.0.0\n  Downloading triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from triton==3.0.0) (3.18.0)\nDownloading triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: triton\n  Attempting uninstall: triton\n    Found existing installation: triton 3.2.0\n    Uninstalling triton-3.2.0:\n      Successfully uninstalled triton-3.2.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntorch 2.6.0+cu124 requires triton==3.2.0; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have triton 3.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed triton-3.0.0\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"# import gc, torch, sys\n\n# # 1) Delete big refs you created earlier\n# for name in [\"trainer\",\"model\",\"base\",\"tok_fast\",\"tok_slow\",\"enc\",\"gen\",\"ds\",\"train_tok\",\"val_tok\"]:\n#     if name in globals():\n#         try:\n#             del globals()[name]\n#         except Exception:\n#             pass\n\n# 2) Collect garbage & free CUDA cache\ngc.collect()\nif torch.cuda.is_available():\n    torch.cuda.empty_cache()\n    torch.cuda.ipc_collect()\n\n# # 3) Quick memory check (optional)\n# if torch.cuda.is_available():\n#     used = torch.cuda.memory_allocated()/1024**3\n#     reserved = torch.cuda.memory_reserved()/1024**3\n#     print(f\"After cleanup — used: {used:.2f} GB, reserved: {reserved:.2f} GB\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:02:44.351506Z","iopub.execute_input":"2025-09-18T12:02:44.352205Z","iopub.status.idle":"2025-09-18T12:02:44.789128Z","shell.execute_reply.started":"2025-09-18T12:02:44.352179Z","shell.execute_reply":"2025-09-18T12:02:44.788198Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"from peft import prepare_model_for_kbit_training\n\n# -------------------- Load 4-bit base & wrap with LoRA --------------------\nDTYPE = torch.bfloat16 if torch.cuda.is_available() and torch.cuda.get_device_capability()[0] >= 8 else torch.float16\nbnb_cfg = BitsAndBytesConfig(load_in_4bit=True,\n                             bnb_4bit_compute_dtype=DTYPE,\n                             bnb_4bit_use_double_quant=True,\n                             bnb_4bit_quant_type=\"nf4\")\n\nbase = AutoModelForCausalLM.from_pretrained(\n    BASE_MODEL,\n    quantization_config=bnb_cfg,\n    torch_dtype=DTYPE,\n    device_map={\"\": 0} if torch.cuda.is_available() else \"auto\",\n    low_cpu_mem_usage=True\n)\n# Resize embeddings to include new class tokens\nbase.resize_token_embeddings(len(tokenizer))\nbase = prepare_model_for_kbit_training(base)\n\npeft_cfg = LoraConfig(\n    r=16, lora_alpha=32, lora_dropout=0.05,\n    target_modules=[\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\",\"gate_proj\",\"up_proj\",\"down_proj\"],  # common for LLaMA/Mistral-like\n    task_type=TaskType.CAUSAL_LM,\n)\nmodel = get_peft_model(base, peft_cfg)\nmodel.config.use_cache = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T08:42:52.329298Z","iopub.execute_input":"2025-09-18T08:42:52.329709Z","iopub.status.idle":"2025-09-18T08:45:49.464814Z","shell.execute_reply.started":"2025-09-18T08:42:52.329680Z","shell.execute_reply":"2025-09-18T08:45:49.464014Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/712 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c6f7e6e25394ee59d72d218f6f439df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09f5d985df8e414ab033991fcc0c1d2f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"082c8ef2f8a3459f93421ee5d0aae7ad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00004.safetensors:   0%|          | 0.00/4.87G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4179897848cf49859e120970a1e5ca8f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00004.safetensors:   0%|          | 0.00/4.93G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"60789f70d51a4eefb1b09633155e22c6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00004.safetensors:   0%|          | 0.00/4.33G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"292f1ba292d64245918310cf777f53b6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00004.safetensors:   0%|          | 0.00/1.09G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"166590dcd0194969805523400923637a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0b3579421d5453ab4d059fbfdf7d38b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/242 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd58982549d04a1eb535925e8e0c2a8d"}},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"# Optional but helpful diagnostics\nmodel.print_trainable_parameters()  # should show a nonzero % trainable\nprint(\"Any trainable params?\", any(p.requires_grad for p in model.parameters()))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T08:45:49.465673Z","iopub.execute_input":"2025-09-18T08:45:49.465891Z","iopub.status.idle":"2025-09-18T08:45:49.474458Z","shell.execute_reply.started":"2025-09-18T08:45:49.465875Z","shell.execute_reply":"2025-09-18T08:45:49.473696Z"}},"outputs":[{"name":"stdout","text":"trainable params: 40,370,176 || all params: 7,653,184,000 || trainable%: 0.5275\nAny trainable params? True\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"for i in range(len(ds[\"train\"])):\n    ex = ds[\"train\"][i]\n    if not (isinstance(ex[\"labels\"], list) and len(ex[\"labels\"]) == len(ex[\"input_ids\"])\n            and all(isinstance(x, int) for x in ex[\"labels\"])):\n        print(\"Bad row:\", i, type(ex[\"labels\"]), len(ex[\"labels\"]), len(ex[\"input_ids\"]))\n        break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T08:45:49.475113Z","iopub.execute_input":"2025-09-18T08:45:49.475380Z","iopub.status.idle":"2025-09-18T08:45:50.583600Z","shell.execute_reply.started":"2025-09-18T08:45:49.475360Z","shell.execute_reply":"2025-09-18T08:45:50.582983Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"from trl import SFTTrainer, SFTConfig\nsft_cfg = SFTConfig(\n    output_dir=\"qlora_cls\",\n    num_train_epochs=2,\n    per_device_train_batch_size=8,\n    gradient_accumulation_steps=16,\n    learning_rate=2e-4,\n    lr_scheduler_type=\"cosine\",\n    warmup_ratio=0.03,\n    logging_steps=14,\n    save_steps=500,\n    bf16=(DTYPE==torch.bfloat16),\n    fp16=(DTYPE==torch.float16),\n    gradient_checkpointing=False,\n    optim=\"adamw_torch\",\n    max_seq_length=384,\n    report_to=[],\n)\ntrainer = SFTTrainer(\n    model=model,\n    args=sft_cfg,\n    train_dataset=ds[\"train\"],\n    eval_dataset=ds[\"validation\"],\n    tokenizer=tokenizer,\n    data_collator=collate_fn,   # use custom collator that pads labels with -100\n    packing=False,\n)\ntrainer.train()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T08:45:50.584256Z","iopub.execute_input":"2025-09-18T08:45:50.584465Z","iopub.status.idle":"2025-09-18T12:00:05.777487Z","shell.execute_reply.started":"2025-09-18T08:45:50.584449Z","shell.execute_reply":"2025-09-18T12:00:05.776672Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/accelerate/accelerator.py:488: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [58/58 3:10:49, Epoch 1/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>14</td>\n      <td>9.250500</td>\n    </tr>\n    <tr>\n      <td>28</td>\n      <td>0.708900</td>\n    </tr>\n    <tr>\n      <td>42</td>\n      <td>0.424900</td>\n    </tr>\n    <tr>\n      <td>56</td>\n      <td>0.359600</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:209: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=58, training_loss=2.6058413201364976, metrics={'train_runtime': 11652.8703, 'train_samples_per_second': 0.647, 'train_steps_per_second': 0.005, 'total_flos': 7.283218325354496e+16, 'train_loss': 2.6058413201364976, 'epoch': 1.9661016949152543})"},"metadata":{}}],"execution_count":32},{"cell_type":"code","source":"\n# -------------------- Constrained decoding for evaluation --------------------\nclass LabelOnlyProcessor(LogitsProcessor):\n    def __init__(self, allowed_ids, device=\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n        self.allowed = torch.tensor(allowed_ids, device=device)\n    def __call__(self, input_ids, scores):\n        # Mask everything except class tokens\n        mask = torch.full_like(scores, float(\"-inf\"))\n        mask.index_fill_(1, self.allowed, 0.0)\n        return scores + mask\n\nallowed_ids = tokenizer.convert_tokens_to_ids(list(label_to_token.values()))\nprocessor = LabelOnlyProcessor(allowed_ids)\n\ndef predict_labels(texts, model, batch_size=32, max_input_tokens=512):\n    preds = []\n    for i in tqdm(range(0, len(texts), batch_size)):\n        batch = texts[i:i+batch_size]\n        prompts = [build_chat_prompt(t) for t in batch]\n        enc = tokenizer(prompts, return_tensors=\"pt\",\n                        padding=True, truncation=True, max_length=max_input_tokens).to(model.device)\n        with torch.inference_mode():\n            gen = model.generate(**enc,\n                                 max_new_tokens=1,           # we want exactly one label token\n                                 do_sample=False,            # greedy\n                                 logits_processor=[processor],\n                                 eos_token_id=tokenizer.eos_token_id,\n                                 pad_token_id=tokenizer.pad_token_id,\n                                 use_cache=True)\n        # take only new tokens after the prompt\n        new = gen[:, enc[\"input_ids\"].shape[1]:]\n        toks = tokenizer.batch_decode(new, skip_special_tokens=False)\n        # map token -> class (first token)\n        for t in toks:\n            tok = t.strip().split()[0] if t.strip() else \"\"\n            preds.append(token_to_label.get(tok, \"нет товара\"))\n    return preds\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:00:05.778478Z","iopub.execute_input":"2025-09-18T12:00:05.778755Z","iopub.status.idle":"2025-09-18T12:00:05.786767Z","shell.execute_reply.started":"2025-09-18T12:00:05.778731Z","shell.execute_reply":"2025-09-18T12:00:05.785925Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"from tqdm import tqdm\n\n# -------------------- Weighted F1 on validation --------------------\ntokenizer.padding_side = \"left\"\ny_true = val_df[\"label\"].tolist()\ny_pred = predict_labels(val_df[\"text\"].tolist(), model=model, batch_size=16)\n\n\nprint(classification_report(y_true, y_pred, labels=CLASSES, digits=4))\nprint(\"Weighted F1:\", f1_score(y_true, y_pred, average=\"weighted\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:03:31.560442Z","iopub.execute_input":"2025-09-18T12:03:31.560725Z","iopub.status.idle":"2025-09-18T12:08:49.226946Z","shell.execute_reply.started":"2025-09-18T12:03:31.560705Z","shell.execute_reply":"2025-09-18T12:08:49.226105Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 42/42 [05:17<00:00,  7.56s/it]","output_type":"stream"},{"name":"stdout","text":"                        precision    recall  f1-score   support\n\n                 обувь     0.8571    0.6667    0.7500        27\n                одежда     0.8596    0.9689    0.9110       354\n                посуда     1.0000    1.0000    1.0000        16\n              текстиль     0.7143    0.4348    0.5405        23\n      товары для детей     0.9286    0.8125    0.8667        16\nукрашения и аксессуары     1.0000    0.5500    0.7097        20\n           электроника     1.0000    1.0000    1.0000        15\n            нет товара     0.9091    0.8205    0.8625       195\n\n              accuracy                         0.8799       666\n             macro avg     0.9086    0.7817    0.8301       666\n          weighted avg     0.8814    0.8799    0.8745       666\n\nWeighted F1: 0.8745325969953918\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"y_test_preds = predict_labels(df_test[\"text\"].tolist(), model=model, batch_size=16)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T12:17:43.780157Z","iopub.execute_input":"2025-09-18T12:17:43.780519Z","iopub.status.idle":"2025-09-18T13:14:30.035515Z","shell.execute_reply.started":"2025-09-18T12:17:43.780498Z","shell.execute_reply":"2025-09-18T13:14:30.034888Z"}},"outputs":[{"name":"stderr","text":"  0%|          | 0/455 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:572: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `70` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n100%|██████████| 455/455 [56:46<00:00,  7.49s/it]\n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"import csv\ndf_test_preds = pd.DataFrame(columns=['category'], data=y_test_preds)\ndf_test_preds.to_csv('test_preds.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T13:18:11.394593Z","iopub.execute_input":"2025-09-18T13:18:11.395252Z","iopub.status.idle":"2025-09-18T13:18:11.404735Z","shell.execute_reply.started":"2025-09-18T13:18:11.395229Z","shell.execute_reply":"2025-09-18T13:18:11.404047Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"df_test_preds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T13:18:14.043046Z","iopub.execute_input":"2025-09-18T13:18:14.043749Z","iopub.status.idle":"2025-09-18T13:18:14.050910Z","shell.execute_reply.started":"2025-09-18T13:18:14.043724Z","shell.execute_reply":"2025-09-18T13:18:14.050221Z"}},"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"        category\n0     нет товара\n1         одежда\n2         одежда\n3         одежда\n4         одежда\n...          ...\n7271      одежда\n7272  нет товара\n7273      одежда\n7274      одежда\n7275      одежда\n\n[7276 rows x 1 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>нет товара</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>одежда</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>одежда</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>одежда</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>одежда</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7271</th>\n      <td>одежда</td>\n    </tr>\n    <tr>\n      <th>7272</th>\n      <td>нет товара</td>\n    </tr>\n    <tr>\n      <th>7273</th>\n      <td>одежда</td>\n    </tr>\n    <tr>\n      <th>7274</th>\n      <td>одежда</td>\n    </tr>\n    <tr>\n      <th>7275</th>\n      <td>одежда</td>\n    </tr>\n  </tbody>\n</table>\n<p>7276 rows × 1 columns</p>\n</div>"},"metadata":{}}],"execution_count":50},{"cell_type":"code","source":"import os, json\n\nOUT_DIR = \"qlora_cls_adapter\"\n\n# 1) Save the PEFT adapter weights/config (small)\nmodel.save_pretrained(OUT_DIR)          # or: trainer.save_model(OUT_DIR)\n\n# 2) Save tokenizer (so special class tokens are preserved)\ntokenizer.save_pretrained(OUT_DIR)\n\n# 3) Save your label↔token mapping for inference\nwith open(os.path.join(OUT_DIR, \"label_tokens.json\"), \"w\", encoding=\"utf-8\") as f:\n    json.dump({\"label_to_token\": label_to_token}, f, ensure_ascii=False, indent=2)\n\n# 4) (Optional) Save training state/args for reproducibility\ntrainer.save_state()\nwith open(os.path.join(OUT_DIR, \"training_args.json\"), \"w\") as f:\n    f.write(trainer.args.to_json_string())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T07:45:58.920036Z","iopub.execute_input":"2025-09-17T07:45:58.920299Z","iopub.status.idle":"2025-09-17T07:46:13.177800Z","shell.execute_reply.started":"2025-09-17T07:45:58.920269Z","shell.execute_reply":"2025-09-17T07:46:13.177033Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:209: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"!zip -r qlora_cls.zip /kaggle/working/qlora_cls\n!zip -r qlora_cls_adapter /kaggle/working/qlora_cls_adapter","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T07:58:02.374914Z","iopub.execute_input":"2025-09-17T07:58:02.375540Z","iopub.status.idle":"2025-09-17T08:10:41.890592Z","shell.execute_reply.started":"2025-09-17T07:58:02.375498Z","shell.execute_reply":"2025-09-17T08:10:41.889807Z"}},"outputs":[{"name":"stdout","text":"  adding: kaggle/working/qlora_cls/ (stored 0%)\n  adding: kaggle/working/qlora_cls/trainer_state.json (deflated 59%)\n  adding: kaggle/working/qlora_cls/checkpoint-58/ (stored 0%)\n  adding: kaggle/working/qlora_cls/checkpoint-58/tokenizer_config.json (deflated 89%)\n  adding: kaggle/working/qlora_cls/checkpoint-58/vocab.json (deflated 69%)\n  adding: kaggle/working/qlora_cls/checkpoint-58/adapter_model.safetensors^C\n\n\n\nzip error: Interrupted (aborting)\n  adding: kaggle/working/qlora_cls_adapter/ (stored 0%)\n  adding: kaggle/working/qlora_cls_adapter/tokenizer_config.json (deflated 89%)\n  adding: kaggle/working/qlora_cls_adapter/vocab.json (deflated 69%)\n  adding: kaggle/working/qlora_cls_adapter/adapter_model.safetensors^C\n\n\n\nzip error: Interrupted (aborting)\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"model_qlora = model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T07:55:16.630927Z","iopub.execute_input":"2025-09-17T07:55:16.631571Z","iopub.status.idle":"2025-09-17T07:55:16.634915Z","shell.execute_reply.started":"2025-09-17T07:55:16.631548Z","shell.execute_reply":"2025-09-17T07:55:16.634289Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"import json, torch\nfrom peft import AutoPeftModelForCausalLM\nfrom transformers import AutoTokenizer, BitsAndBytesConfig\n\nDTYPE = torch.float16 if torch.cuda.get_device_capability()[0] < 8 else torch.bfloat16\nbnb_cfg = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_compute_dtype=DTYPE,\n                             bnb_4bit_use_double_quant=True, bnb_4bit_quant_type=\"nf4\")\n\nADAPTER_DIR = \"qlora_cls_adapter\"\n\n# AutoPeftModel will read base_model_name_or_path from the adapter config and load base+adapter\nmodel = AutoPeftModelForCausalLM.from_pretrained(\n    ADAPTER_DIR, quantization_config=bnb_cfg, device_map=\"auto\"\n).eval()\n\ntokenizer = AutoTokenizer.from_pretrained(ADAPTER_DIR, use_fast=False)\nwith open(f\"{ADAPTER_DIR}/label_tokens.json\", \"r\", encoding=\"utf-8\") as f:\n    label_to_token = json.load(f)[\"label_to_token\"]\ntoken_to_label = {v:k for k,v in label_to_token.items()}\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Разметка тестового набора","metadata":{}},{"cell_type":"code","source":"from transformers import BitsAndBytesConfig\nDTYPE = torch.bfloat16 if torch.cuda.get_device_capability()[0] >= 8 else torch.float16\nbnb_cfg = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_compute_dtype=DTYPE, bnb_4bit_use_double_quant=True, bnb_4bit_quant_type=\"nf4\")\n\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nimport torch\ntorch.manual_seed(42)\n\nfor param in base.parameters():\n    param.requires_grad = False\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T08:10:58.245866Z","iopub.execute_input":"2025-09-17T08:10:58.246150Z","iopub.status.idle":"2025-09-17T08:10:58.260816Z","shell.execute_reply.started":"2025-09-17T08:10:58.246119Z","shell.execute_reply":"2025-09-17T08:10:58.260114Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"model_name = \"t-tech/T-lite-it-1.0\"\ntokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)\ntokenizer.pad_token_id = tokenizer.eos_token_id","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T08:40:56.319026Z","iopub.execute_input":"2025-09-17T08:40:56.319739Z","iopub.status.idle":"2025-09-17T08:40:56.655208Z","shell.execute_reply.started":"2025-09-17T08:40:56.319717Z","shell.execute_reply":"2025-09-17T08:40:56.654398Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"classificator_prompt = '''\nSystem: Ты — аккуратный классификатор отзывов маркетплейса по категориям товаров, к которым они относятся.\nДоступные метки:\nобувь,\nодежда,\nпосуда,\nтекстиль,\nтовары для детей,\nукрашения и аксессуары,\nэлектроника,\nнет товара.\n\nПравила:\n- Если отзыв только про доставку/продавца/деньги/спор без товара → \"нет товара\".\n- Если не ясно, какой товар — тоже \"нет товара\".\n- Выбери ровно одну метку.\n\nОтветь строго JSON одной строкой:\n{\"label\": \"<одна метка>\", \"confidence\": 0..1, \"reason\": \"<до 12 слов>\"}\n\nПримеры:\n\nОтзыв: отличная блузка отслеживалась пришла за 10 дней.\nОтвет: {\"label\": \"одежда\", \"confidence\": 1, \"reason\": \"блузка относится к одежде\"}\n\nОтзыв: Лучшая покупка на алиэкспресс !!)))\nОтвет: {\"label\": \"нет товара\", \"confidence\": 1, \"reason\": \"нет никакого описания товара\"}\n\nОтзыв: На фото они матовые, а пришли глянцевые.\nОтвет: {\"label\": \"обувь\", \"confidence\": 0.4, \"reason\": \"матовость и глянцевость в множественном числе, вероятно, относится к обуви\"}\n\nОтзыв: Товар пришёл менее чем за месяц. На мой 44 заказала L пришла необъятных размеров  \nОтвет: {\"label\": \"одежда\", \"confidence\": 0.9, \"reason\": \"Размер L почти всегда относится к одежде\"}\n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T08:11:01.162249Z","iopub.execute_input":"2025-09-17T08:11:01.162499Z","iopub.status.idle":"2025-09-17T08:11:01.166985Z","shell.execute_reply.started":"2025-09-17T08:11:01.162482Z","shell.execute_reply":"2025-09-17T08:11:01.166364Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"import re, json, numpy as np\nfrom tqdm.auto import tqdm\nimport torch\nfrom torch.nn.utils.rnn import pad_sequence\nfrom transformers import AutoTokenizer\n\n# --- tokenizer hygiene ---\n# make sure both pad_token_id and pad_token are set (Qwen2 slow tokenizer can be picky)\nif tokenizer.pad_token_id is None:\n    tokenizer.pad_token_id = tokenizer.eos_token_id\nif tokenizer.pad_token is None:\n    tokenizer.pad_token = tokenizer.eos_token\ntokenizer.padding_side = \"left\"\n\nbase.eval()\n\n# ---- helpers (as before) ----\ndef make_prompt(txt: str) -> str:\n    messages = [\n        {\"role\": \"system\", \"content\": classificator_prompt},\n        {\"role\": \"user\", \"content\": txt},\n    ]\n    return tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n\ndef extract_json(s: str):\n    try:\n        i, j = s.find(\"{\"), s.rfind(\"}\")\n        if i != -1 and j != -1 and j > i:\n            return json.loads(s[i:j+1])\n    except Exception:\n        pass\n    m = re.search(r\"\\{.*\\}\", s, flags=re.S)\n    if m:\n        try:\n            return json.loads(m.group(0))\n        except Exception:\n            return None\n    return None\n\ndef parse_output(text: str):\n    obj = extract_json(text) or {}\n    label = obj.get(\"label\", None)\n    conf  = obj.get(\"confidence\", None)\n    if isinstance(label, str):\n        label = label.strip().lower()\n    if label not in CLASSES:\n        for c in CLASSES:\n            if label and c in label:\n                label = c; break\n    if label not in CLASSES:\n        label = \"нет товара\"\n    try:\n        conf = float(conf)\n        if not (0.0 <= conf <= 1.0):\n            conf = 0.5\n    except Exception:\n        conf = 0.5\n    return label, conf\n\n# --- data ---\ndf_test[\"text\"] = df_test[\"text\"].fillna(\"\").astype(str)\ntexts = df_test[\"text\"].tolist()\n\n# --- generation settings (clean: no sampling-only args) ---\nBATCH_SIZE = 8\nMAX_INPUT_TOKENS = 512\nMAX_NEW_TOKENS = 24   # JSON is short; keep small for speed\n\nGEN_KW = dict(\n    max_new_tokens=MAX_NEW_TOKENS,\n    do_sample=False,                      # greedy\n    eos_token_id=tokenizer.eos_token_id,\n    pad_token_id=tokenizer.pad_token_id,\n    use_cache=True\n)\n\npred_labels, pred_conf = [], []\n\n# safe per-row decode to avoid None tokens from padded matrix\ndef safe_decode(ids_tensor):\n    # filter out any PAD / negative ids before decode\n    ids = ids_tensor.tolist()\n    ids = [i for i in ids if isinstance(i, int) and i >= 0 and i != tokenizer.pad_token_id]\n    if not ids:\n        return \"\"\n    return tokenizer.decode(ids, skip_special_tokens=True)\n\nwith torch.inference_mode():\n    for start in tqdm(range(0, len(texts), BATCH_SIZE), desc=\"LLM labeling\"):\n        batch_texts = texts[start:start+BATCH_SIZE]\n        prompts = [make_prompt(t) for t in batch_texts]\n\n        enc = tokenizer(\n            prompts, return_tensors=\"pt\",\n            padding=True, truncation=True, max_length=MAX_INPUT_TOKENS\n        ).to(base.device)\n\n        input_lengths = enc[\"attention_mask\"].sum(dim=1)\n\n        gen = base.generate(**enc, **GEN_KW)\n\n        # slice only the newly generated tokens\n        new_tokens = [out_ids[in_len:] for out_ids, in_len in zip(gen, input_lengths)]\n\n        # per-sample decode (robust for Qwen2 slow tokenizer)\n        out_texts = [safe_decode(t) for t in new_tokens]\n\n        for out in out_texts:\n            lbl, conf = parse_output(out)\n            pred_labels.append(lbl)\n            pred_conf.append(conf)\n\ndf_test[\"class_from_llm\"] = pred_labels\ndf_test[\"llm_confidence\"] = pred_conf\n\nprint(df_test[\"class_from_llm\"].value_counts(dropna=False))\nprint(f\"Mean confidence: {np.mean(pred_conf):.3f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T08:41:02.327045Z","iopub.execute_input":"2025-09-17T08:41:02.327791Z","iopub.status.idle":"2025-09-17T08:46:34.763812Z","shell.execute_reply.started":"2025-09-17T08:41:02.327765Z","shell.execute_reply":"2025-09-17T08:46:34.762885Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"LLM labeling:   0%|          | 0/910 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14b311daa7db4f31b25e01f9a6821dfb"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:572: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `70` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n  warnings.warn(\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/2922909992.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;31m# per-sample decode (robust for Qwen2 slow tokenizer)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0mout_texts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msafe_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnew_tokens\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mout_texts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/2922909992.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;31m# per-sample decode (robust for Qwen2 slow tokenizer)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0mout_texts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msafe_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnew_tokens\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mout_texts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/2922909992.py\u001b[0m in \u001b[0;36msafe_decode\u001b[0;34m(ids_tensor)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/qwen2/tokenization_qwen2.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, spaces_between_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0;31m# `spaces_between_special_tokens` defaults to True for _decode in slow tokenizers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;31m# and cannot be configured elsewhere, but it should default to False for Qwen2Tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m         return super().decode(\n\u001b[0m\u001b[1;32m    300\u001b[0m             \u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[1;32m   4014\u001b[0m         \u001b[0mtoken_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_py_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4016\u001b[0;31m         return self._decode(\n\u001b[0m\u001b[1;32m   4017\u001b[0m             \u001b[0mtoken_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4018\u001b[0m             \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36m_decode\u001b[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, spaces_between_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcurrent_sub_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcurrent_sub_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m             \u001b[0msub_texts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_tokens_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_sub_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mspaces_between_special_tokens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/qwen2/tokenization_qwen2.py\u001b[0m in \u001b[0;36mconvert_tokens_to_string\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconvert_tokens_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;34m\"\"\"Converts a sequence of tokens (string) in a single string.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyte_decoder\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: sequence item 0: expected str instance, NoneType found"],"ename":"TypeError","evalue":"sequence item 0: expected str instance, NoneType found","output_type":"error"}],"execution_count":46},{"cell_type":"code","source":"df_test.to_parquet(\"test_markup_llm\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"L_test = applier.apply(df=df_test)  # shape (N, num_LFs)\ntest_probs = label_model.predict_proba(L_test)  # (N, 8)\nlf_pred = test_probs.argmax(1)\nlf_conf = test_probs.max(1)\n\ndf_test['prediction_snorkel'] = lf_pred\ndf_test['snorkel_confidence'] = lf_conf\ndf_test[\"snorkel_probs\"] = test_probs.tolist()\n\ndf_test.to_parquet('test_markup_snorkel.parquet')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"p_snorkel = df_test['snorkel_probs'].values\np_snorkel = np.array(list(p_snorkel))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"p_llm = build_llm_probs_from_label(df_test[\"class_from_llm\"], df_test[\"llm_confidence\"], K=len(CLASSES))\ny, conf, p = fuse_probs(p_snorkel, p_llm, llm_conf=df_test[\"llm_confidence\"], tau_low=0.50)\nfinal_labels = [CLASSES[i] for i in y]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_test['label'] = final_labels","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# -------------------- Weighted F1 on validation --------------------\ny_true = df_test[\"label\"].tolist()\ny_pred = predict_labels(df_test[\"text\"].tolist(), model=model_qlora, batch_size=32)\n\nprint(classification_report(y_true, y_pred, labels=CLASSES, digits=4))\nprint(\"Weighted F1:\", f1_score(y_true, y_pred, average=\"weighted\"))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### PEFT","metadata":{}},{"cell_type":"code","source":"base = AutoModelForCausalLM.from_pretrained(BASE_MODEL, torch_dtype=DTYPE, device_map=\"auto\")\nbase.resize_token_embeddings(len(tokenizer))\n\npt_cfg = PromptTuningConfig(\n    task_type=TaskType.CAUSAL_LM,\n    num_virtual_tokens=64,  # 20-100; more = more capacity\n    tokenizer_name_or_path=BASE_MODEL,\n)\nmodel = get_peft_model(base, pt_cfg)\n\nsft_cfg = SFTConfig(\n    output_dir=\"prompt_tune_cls\",\n    num_train_epochs=3,\n    per_device_train_batch_size=4, gradient_accumulation_steps=8,\n    learning_rate=5e-4, warmup_ratio=0.05,\n    logging_steps=20, save_steps=500, bf16=(DTYPE==torch.bfloat16),\n    gradient_checkpointing=True\n)\ntrainer = SFTTrainer(model=model, train_dataset=ds[\"train\"], eval_dataset=ds[\"validation\"],\n                     tokenizer=tokenizer, args=sft_cfg)\ntrainer.train()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Fine-Tuning","metadata":{}},{"cell_type":"code","source":"SMALL_MODEL = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"  # example\ntokenizer = AutoTokenizer.from_pretrained(SMALL_MODEL, use_fast=True)\ntokenizer.add_special_tokens({\"additional_special_tokens\": specials})\nmodel = AutoModelForCausalLM.from_pretrained(SMALL_MODEL, torch_dtype=DTYPE, device_map=\"auto\")\nmodel.resize_token_embeddings(len(tokenizer))\nmodel.gradient_checkpointing_enable()\n\nsft_cfg = SFTConfig(\n    output_dir=\"fullft_cls_small\",\n    num_train_epochs=3,\n    per_device_train_batch_size=4, gradient_accumulation_steps=8,\n    learning_rate=1e-5, weight_decay=0.01, warmup_ratio=0.03,\n    bf16=(DTYPE==torch.bfloat16), logging_steps=20, save_steps=500\n)\ntrainer = SFTTrainer(model=model, train_dataset=ds[\"train\"], eval_dataset=ds[\"validation\"],\n                     tokenizer=tokenizer, args=sft_cfg)\ntrainer.train()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}